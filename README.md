# ğŸ›ï¸ H&M Fashion Recommendatio```
ğŸ“¦ Pipeline de Recommandation H&M Complet (8 Ã‰tapes)
â”œâ”€â”€ ğŸ”§ 00_setup_and_data_loading        # Configuration Google Drive & dÃ©pendances
â”œâ”€â”€ ğŸ“Š 01_Exploration_Donnees          # Analyse sparsitÃ© & distributions
â”œâ”€â”€ ğŸ¯ 02_Echantillonnage_Donnees      # StratÃ©gies Ã©chantillonnage optimales
â”œâ”€â”€ ğŸ”„ 03_Preparation_Donnees          # Mappings & matrices LightFM
â”œâ”€â”€ ğŸ¤– 04_Modele_Collaboratif          # ModÃ¨le collaboratif (WARP, BPR)
â”œâ”€â”€ âš™ï¸ 05_Optimisation_Hyperparametres  # Grid search & validation croisÃ©e
â”œâ”€â”€ ğŸ“Š 06_Evaluation_Modele            # Ã‰valuation approfondie & mÃ©triques
â”œâ”€â”€ ğŸ”— 07_Modele_Hybride               # ModÃ¨le hybride avec features articles
â””â”€â”€ ğŸ¯ 08_Pipeline_Final               # Pipeline complet & dÃ©mo interactive
```e

[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![LightFM](https://img.shields.io/badge/LightFM-1.17+-green.svg)](h### Insights DÃ©couverts
- ğŸ”¬ **SparsitÃ© extrÃªme** : 99.95-99.99% - dÃ©fi majeur pour recommandations
- ğŸ“Š **Distribution power-law** : Peu d'utilisateurs trÃ¨s actifs, majoritÃ© occasionnelle
- ğŸ¯ **Ã‰chantillonnage critique** : StratÃ©gie "CombinÃ©" (actifs + populaires) optimale
- âš¡ **Performance LightFM** : WARP loss function supÃ©rieure pour ranking
- ğŸ”„ **HyperparamÃ¨tres sensibles** : Learning rate et regularization impact fort
- ğŸ’¾ **MÃ©moire optimisÃ©e** : Matrices sparse essentielles pour scalabilitÃ©
- ğŸ”— **ModÃ¨le hybride** : Features articles apportent amÃ©lioration modÃ©rÃ©e mais robustesse
- ğŸ›¡ï¸ **Robustesse critique** : Gestion d'erreurs automatique essentielle en production
- ğŸ†• **Cold-start** : Fallback sur popularitÃ© efficace pour nouveaux utilisateurs
- ğŸ“ˆ **Ã‰valuation multi-niveaux** : MÃ©triques diversifiÃ©es rÃ©vÃ¨lent qualitÃ©s cachÃ©esmaking.lyst.com/lightfm/docs/home.html)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

Un pipeline complet de systÃ¨me de recommandation pour les articles de mode H&M, utilisant des techniques de filtrage collaboratif avec LightFM. Le projet inclut une analyse exploratoire approfondie, des stratÃ©gies d'Ã©chantillonnage intelligentes et une optimisation systÃ©matique des hyperparamÃ¨tres.

## ğŸ“‹ Table des MatiÃ¨res

- [ğŸ¯ Objectifs](#-objectifs)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸ“Š Dataset](#-dataset)
- [ğŸš€ Installation](#-installation)
- [ğŸ“– Utilisation](#-utilisation)
- [ğŸ“‚ Structure du Projet](#-structure-du-projet)
- [ğŸ”¬ MÃ©thodologie](#-mÃ©thodologie)
- [ğŸ“ˆ RÃ©sultats](#-rÃ©sultats)
- [ğŸ¤ Contribution](#-contribution)

## ğŸ¯ StratÃ©gies d'Ã‰chantillonnage ImplÃ©mentÃ©es

| StratÃ©gie | Description | Avantages |
|-----------|-------------|----------|
| **Utilisateurs Actifs** | â‰¥5 interactions par user | RÃ©duit cold start users |
| **Articles Populaires** | â‰¥10 interactions par item | Patterns plus clairs |
| **CombinÃ©** | Actifs + Populaires | Ã‰quilibre optimal |
| **AlÃ©atoire** | Simple random sampling | Baseline comparison |
| **StratifiÃ© Temporel** | Ã‰chantillon par pÃ©riode | PrÃ©serve saisonnalitÃ© |

## ğŸ¯ CaractÃ©ristiques Techniques AvancÃ©es

Ce projet implÃ©mente un systÃ¨me de recommandation de mode pour H&M avec les objectifs suivants :

- **Personnalisation** : Recommandations adaptÃ©es aux prÃ©fÃ©rences individuelles
- **ScalabilitÃ©** : Pipeline optimisÃ© pour traiter de gros volumes de donnÃ©es
- **Performance** : ModÃ¨les hybrides combinant filtrage collaboratif et contenu
- **ExpÃ©rimentation** : Framework pour tester diffÃ©rentes approches et hyperparamÃ¨tres

## ğŸ—ï¸ Architecture

```
ğŸ“¦ Pipeline de Recommandation H&M
â”œâ”€â”€ ï¿½ 00_setup_and_data_loading      # Configuration Google Drive & deps
â”œâ”€â”€ ğŸ“Š 01_Exploration_Donnees        # Analyse sparsitÃ© & distributions
â”œâ”€â”€ ğŸ¯ 02_Echantillonnage_Donnees    # StratÃ©gies Ã©chantillonnage optimales
â”œâ”€â”€ ï¿½ 03_Preparation_Donnees        # Mappings & matrices LightFM
â”œâ”€â”€ ğŸ¤– 04_Modele_Collaboratif        # ModÃ¨le collaboratif (WARP, BPR)
â””â”€â”€ âš™ï¸ 05_Optimisation_Hyperparametres # Grid search & validation croisÃ©e
```

## ğŸ“Š Dataset

Le projet utilise le dataset H&M Personalized Fashion Recommendations comprenant :

- **Transactions** : Historique d'achats des clients
- **Articles** : MÃ©tadonnÃ©es des produits (catÃ©gorie, couleur, prix, etc.)
- **Customers** : Informations dÃ©mographiques des clients

### CaractÃ©ristiques
- **31M+ transactions** sur 2 ans (septembre 2018 - septembre 2020)
- **105K+ articles uniques**
- **1.4M+ clients actifs**
- **SparsitÃ© trÃ¨s Ã©levÃ©e** (~99.95% - 99.99%)
- **Ã‰chantillonnage intelligent** : Focus sur utilisateurs actifs (â‰¥5 interactions) et articles populaires (â‰¥10 interactions)

## ğŸš€ Installation

### PrÃ©requis
- Python 3.8+
- Jupyter Notebook
- Google Colab (recommandÃ©)

### Installation des dÃ©pendances

```bash
# Clone du repository
git clone https://github.com/realnribal/hm-fashion-recommendation-pipeline.git
cd hm-fashion-recommendation-pipeline

# Installation des packages Python
pip install -r requirements.txt
```

### Packages principaux
```
# Installation via notebooks (Google Colab)
lightfm  # Version fork compatible
pandas
numpy
scipy
scikit-learn
matplotlib
seaborn
tqdm
pickle (built-in)
```

## ğŸ“– Utilisation

### 1. Configuration et chargement des donnÃ©es
```bash
jupyter notebook 00_setup_and_data_loading.ipynb
```

### 2. Exploration des donnÃ©es
```bash
jupyter notebook 01_Exploration_Donnees.ipynb
```

### 3. Ã‰chantillonnage stratÃ©gique
```bash
jupyter notebook 02_Echantillonnage_Donnees.ipynb
```

### 4. PrÃ©paration des donnÃ©es
```bash
jupyter notebook 03_Preparation_Donnees.ipynb
```

### 5. ModÃ©lisation collaborative
```bash
jupyter notebook 04_Modele_Collaboratif.ipynb
```

### 6. Optimisation des hyperparamÃ¨tres
```bash
jupyter notebook 05_Optimisation_Hyperparametres.ipynb
```

### 7. Ã‰valuation approfondie du modÃ¨le
```bash
jupyter notebook 06_Evaluation_Modele.ipynb
```

### 8. ModÃ¨le hybride avec features
```bash
jupyter notebook 07_Modele_Hybride.ipynb
```

### 9. Pipeline final et dÃ©mo
```bash
jupyter notebook 08_Pipeline_Final.ipynb
```

## ğŸ“‚ Structure du Projet

```
hm-fashion-recommendation-pipeline/
â”‚
â”œâ”€â”€ ğŸ““ Notebooks
â”‚   â”œâ”€â”€ 00_setup_and_data_loading.ipynb         # Configuration et chargement
â”‚   â”œâ”€â”€ 01_Exploration_Donnees.ipynb            # Analyse exploratoire
â”‚   â”œâ”€â”€ 02_Echantillonnage_Donnees.ipynb        # StratÃ©gies d'Ã©chantillonnage
â”‚   â”œâ”€â”€ 03_Preparation_Donnees.ipynb            # Preprocessing des donnÃ©es
â”‚   â”œâ”€â”€ 04_Modele_Collaboratif.ipynb            # ModÃ©lisation LightFM
â”‚   â”œâ”€â”€ 05_Optimisation_Hyperparametres.ipynb   # Tuning des paramÃ¨tres
â”‚   â”œâ”€â”€ 06_Evaluation_Modele.ipynb              # Ã‰valuation approfondie
â”‚   â”œâ”€â”€ 07_Modele_Hybride.ipynb                 # ModÃ¨le avec features articles
â”‚   â””â”€â”€ 08_Pipeline_Final.ipynb                 # Pipeline complet & dÃ©mo
â”‚
â”œâ”€â”€ ğŸ“ data/                                 # DonnÃ©es brutes et traitÃ©es
â”‚   â”œâ”€â”€ raw/                                # DonnÃ©es originales H&M
â”‚   â”œâ”€â”€ processed/                          # DonnÃ©es preprocessÃ©es
â”‚   â””â”€â”€ samples/                            # Ã‰chantillons pour dÃ©veloppement
â”‚
â”œâ”€â”€ ğŸ“ outputs/                             # RÃ©sultats et artefacts
â”‚   â”œâ”€â”€ figures/                            # Visualisations
â”‚   â”œâ”€â”€ models/                             # ModÃ¨les entraÃ®nÃ©s
â”‚   â””â”€â”€ results/                            # MÃ©triques et rapports
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt                      # DÃ©pendances Python
â””â”€â”€ ğŸ“– README.md                            # Documentation
```

## ğŸ”¬ MÃ©thodologie

### 1. Configuration & Chargement (Notebook 00)
- **Google Drive** : Montage et configuration des chemins
- **Dependencies** : Installation automatique LightFM et dÃ©pendances
- **Structure** : CrÃ©ation automatique des dossiers de sortie

### 2. Exploration des DonnÃ©es (Notebook 01)
- **Analyse de sparsitÃ©** : Calcul prÃ©cis (~99.95% sparsitÃ©)
- **Distributions** : Patterns utilisateurs/articles avec visualisations
- **Quality assessment** : Identification des caractÃ©ristiques clÃ©s
- **Visualisation** : Matrices de sparsitÃ© et distributions

### 3. Ã‰chantillonnage StratÃ©gique (Notebook 02)
- **5 StratÃ©gies** : Utilisateurs actifs, articles populaires, combinÃ©, alÃ©atoire, stratifiÃ© temporel
- **Comparaison quantitative** : Scoring automatique des Ã©chantillons
- **Tailles variables** : Tests 1K, 5K, 10K, 50K, 100K interactions
- **SÃ©lection optimale** : Choix basÃ© sur critÃ¨res de performance

### 4. Preprocessing LightFM (Notebook 03)
- **IDMapper** : Classe custom pour mappings user/item vers entiers
- **Matrices sparse** : GÃ©nÃ©ration COO/CSR pour LightFM
- **Features articles** : Encodage catÃ©gories, prix, descriptions
- **Train/Test split** : Division temporelle prÃ©servant chronologie

### 5. ModÃ©lisation Collaborative (Notebook 04)
- **LightFM** : ModÃ¨le collaboratif pur (sans features)
- **Loss functions** : Tests WARP, BPR, Logistic avec comparaison
- **MÃ©triques** : Precision@K, Recall@K, AUC automatisÃ©es
- **Ã‰valuation** : Validation sur Ã©chantillons test

### 6. Optimisation HyperparamÃ¨tres (Notebook 05)
- **Grid Search** : Exploration systÃ©matique learning_rate, no_components, regularization
- **Validation croisÃ©e** : Tests multiples configurations
- **MÃ©triques comparatives** : SÃ©lection modÃ¨le optimal
- **Sauvegarde** : Persistance meilleur modÃ¨le

### 7. Ã‰valuation Approfondie (Notebook 06)
- **MÃ©triques multiples** : Precision@K, Recall@K, NDCG, AUC
- **Segmentation utilisateurs** : Analyse par niveau d'activitÃ©
- **DiversitÃ© & NouveautÃ©** : Tests qualitÃ© recommandations
- **Cold-start analysis** : Performance nouveaux utilisateurs/articles

### 8. ModÃ¨le Hybride (Notebook 07)
- **Features articles** : IntÃ©gration mÃ©tadonnÃ©es (catÃ©gorie, couleur, prix)
- **Comparaison hybride vs collaboratif** : Mesure amÃ©lioration
- **Gestion compatibilitÃ©** : Fallback automatique si erreurs features
- **Tests cold-start amÃ©liorÃ©s** : Validation robustesse

### 9. Pipeline Final (Notebook 08)
- **SystÃ¨me robuste** : Gestion d'erreurs et fallbacks automatiques
- **Interface recommandation** : Classe H2MRecommendationSystem
- **DÃ©mo interactive** : Tests sur utilisateurs variÃ©s
- **Pipeline production-ready** : Code optimisÃ© et documentÃ©

## ğŸ¯ CaractÃ©ristiques Techniques AvancÃ©es

### Pipeline d'Ã‰valuation ComplÃ¨te
- **MÃ©triques automatisÃ©es** : Precision@K, Recall@K, AUC, NDCG
- **Segmentation intelligente** : Analyse par profil utilisateur
- **Tests diversitÃ©** : Mesure variÃ©tÃ© recommandations
- **Cold-start robuste** : Gestion nouveaux utilisateurs/articles

### ModÃ¨le Hybride Intelligent
| CaractÃ©ristique | ImplÃ©mentation |
|-----------------|----------------|
| **Features articles** | CatÃ©gorie, couleur, prix, description |
| **CompatibilitÃ©** | Fallback automatique vers collaboratif |
| **Identity features** | Matrice identitÃ© + features custom |
| **Gestion erreurs** | SystÃ¨me robuste avec alternatives |

### SystÃ¨me de Recommandation Production
- **Classe H2MRecommendationSystem** : Interface unifiÃ©e
- **Gestion d'erreurs** : Fallbacks automatiques Ã  tous niveaux
- **Nouveaux utilisateurs** : Recommandations basÃ©es popularitÃ©
- **Analyse profil** : Extraction caractÃ©ristiques utilisateur

## ï¿½ Pipeline de Performance

### MÃ©triques AutomatisÃ©es
| MÃ©trique | Description | ImplÃ©mentation |
|----------|-------------|----------------|
| **Precision@K** | PrÃ©cision top-K recommandations | `lightfm.evaluation.precision_at_k` |
| **Recall@K** | Rappel top-K recommandations | `lightfm.evaluation.recall_at_k` |
| **AUC** | Area Under Curve | `lightfm.evaluation.auc_score` |
| **NDCG** | Normalized Discounted Cumulative Gain | Custom implementation |
| **DiversitÃ©** | VariÃ©tÃ© catÃ©gories recommandÃ©es | Analyse post-traitement |

### Robustesse SystÃ¨me
- **Grid Search** : Test automatique combinaisons hyperparamÃ¨tres
- **Validation CroisÃ©e** : Ã‰valuation robuste performance
- **Sauvegarde Automatique** : Persistance rÃ©sultats et modÃ¨les
- **Fallbacks intelligents** : Alternatives automatiques en cas d'erreur

### Insights DÃ©couverts
- ğŸ•³ï¸ **SparsitÃ© extrÃªme** : 99.95-99.99% - dÃ©fi majeur pour recommandations
- ğŸ“Š **Distribution power-law** : Peu d'utilisateurs trÃ¨s actifs, majoritÃ© occasionnelle
- ğŸ¯ **Ã‰chantillonnage critique** : StratÃ©gie "CombinÃ©" (actifs + populaires) optimale
- âš¡ **Performance LightFM** : WARP loss function supÃ©rieure pour ranking
- ğŸ”„ **HyperparamÃ¨tres sensibles** : Learning rate et regularization impact fort
- ğŸ’¾ **MÃ©moire optimisÃ©e** : Matrices sparse essentielles pour scalabilitÃ©

## ğŸ”§ Configuration Google Colab

Ce projet est **optimisÃ© pour Google Colab** avec gestion automatique des erreurs :

### 1. Montage Google Drive (standardisÃ© dans tous notebooks)
```python
print("ğŸ”— Connexion Ã  Google Drive...")
from google.colab import drive
drive.mount('/content/drive')
print("âœ… Google Drive montÃ© avec succÃ¨s")
```

### 2. Configuration des chemins (identique partout)
```python
BASE_PATH = "/content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys"
DATA_PATH = f"{BASE_PATH}/data"
OUTPUTS_PATH = f"{BASE_PATH}/outputs"

# CrÃ©ation automatique structure dossiers
directories_to_create = [
    f"{OUTPUTS_PATH}/models",
    f"{OUTPUTS_PATH}/figures", 
    f"{OUTPUTS_PATH}/metrics",
    f"{OUTPUTS_PATH}/samples"
]
```

### 3. Installation LightFM (version fork compatible)
```python
# Dans chaque notebook nÃ©cessitant LightFM
!pip install git+https://github.com/daviddavo/lightfm
!pip install -q tqdm
```

### 4. Persistance Robuste
- **Pickle automatique** : Sauvegarde intelligente entre notebooks
- **Gestion d'erreurs** : Fallbacks si fichiers manquants
- **CompatibilitÃ©** : VÃ©rification versions et formats
- **Pipeline continu** : Chaque notebook utilise sorties prÃ©cÃ©dentes

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Pour contribuer :

1. **Fork** le projet
2. **CrÃ©er** une branche feature (`git checkout -b feature/AmazingFeature`)
3. **Commit** vos changements (`git commit -m 'Add some AmazingFeature'`)
4. **Push** vers la branche (`git push origin feature/AmazingFeature`)
5. **Ouvrir** une Pull Request

## ğŸ“ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ‘¥ Auteurs

- **Votre Nom** - *DÃ©veloppement initial* - [@realnribal](https://github.com/realnribal)

## ğŸ™ Remerciements

- Dataset H&M Personalized Fashion Recommendations
- Ã‰quipe LightFM pour l'excellent framework
- CommunautÃ© Kaggle pour les insights et discussions

---

**â­ Si ce projet vous a Ã©tÃ© utile, n'hÃ©sitez pas Ã  lui donner une Ã©toile !**