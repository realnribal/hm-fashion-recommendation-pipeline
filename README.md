# ğŸ›ï¸ H&M Fashion Recommendation Pipeline

[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![LightFM](https://img.shields.io/badge/LightFM-1.17+-green.svg)](https://making.lyst.com/lightfm/docs/home.html)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

Un pipeline complet de systÃ¨me de recommandation pour les articles de mode H&M, utilisant des techniques de filtrage collaboratif et hybride avec LightFM.

## ğŸ“‹ Table des MatiÃ¨res

- [ğŸ¯ Objectifs](#-objectifs)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸ“Š Dataset](#-dataset)
- [ğŸš€ Installation](#-installation)
- [ğŸ“– Utilisation](#-utilisation)
- [ğŸ“‚ Structure du Projet](#-structure-du-projet)
- [ğŸ”¬ MÃ©thodologie](#-mÃ©thodologie)
- [ğŸ“ˆ RÃ©sultats](#-rÃ©sultats)
- [ğŸ¤ Contribution](#-contribution)

## ğŸ¯ Objectifs

Ce projet implÃ©mente un systÃ¨me de recommandation de mode pour H&M avec les objectifs suivants :

- **Personnalisation** : Recommandations adaptÃ©es aux prÃ©fÃ©rences individuelles
- **ScalabilitÃ©** : Pipeline optimisÃ© pour traiter de gros volumes de donnÃ©es
- **Performance** : ModÃ¨les hybrides combinant filtrage collaboratif et contenu
- **ExpÃ©rimentation** : Framework pour tester diffÃ©rentes approches et hyperparamÃ¨tres

## ğŸ—ï¸ Architecture

```
ğŸ“¦ Pipeline de Recommandation
â”œâ”€â”€ ğŸ“Š Exploration des DonnÃ©es
â”œâ”€â”€ ğŸ¯ Ã‰chantillonnage StratÃ©gique
â”œâ”€â”€ ğŸ”§ Preprocessing & Feature Engineering
â”œâ”€â”€ ğŸ¤– ModÃ©lisation (LightFM)
â”œâ”€â”€ âš¡ Optimisation des HyperparamÃ¨tres
â””â”€â”€ ğŸ“ˆ Ã‰valuation & MÃ©triques
```

## ğŸ“Š Dataset

Le projet utilise le dataset H&M Personalized Fashion Recommendations comprenant :

- **Transactions** : Historique d'achats des clients
- **Articles** : MÃ©tadonnÃ©es des produits (catÃ©gorie, couleur, prix, etc.)
- **Customers** : Informations dÃ©mographiques des clients

### CaractÃ©ristiques
- **31M+ transactions** sur 2 ans
- **105K+ articles uniques**
- **1.4M+ clients actifs**
- **SparsitÃ© Ã©levÃ©e** (~99.9%)

## ğŸš€ Installation

### PrÃ©requis
- Python 3.8+
- Jupyter Notebook
- Google Colab (recommandÃ©)

### Installation des dÃ©pendances

```bash
# Clone du repository
git clone https://github.com/realnribal/hm-fashion-recommendation-pipeline.git
cd hm-fashion-recommendation-pipeline

# Installation des packages Python
pip install -r requirements.txt
```

### Packages principaux
```
lightfm>=1.17
pandas>=1.3.0
numpy>=1.21.0
scikit-learn>=1.0.0
matplotlib>=3.5.0
seaborn>=0.11.0
tqdm>=4.62.0
```

## ğŸ“– Utilisation

### 1. Configuration et chargement des donnÃ©es
```bash
jupyter notebook 00_setup_and_data_loading.ipynb
```

### 2. Exploration des donnÃ©es
```bash
jupyter notebook 01_Exploration_Donnees.ipynb
```

### 3. Ã‰chantillonnage stratÃ©gique
```bash
jupyter notebook 02_Echantillonnage_Donnees.ipynb
```

### 4. PrÃ©paration des donnÃ©es
```bash
jupyter notebook 03_Preparation_Donnees.ipynb
```

### 5. ModÃ©lisation collaborative
```bash
jupyter notebook 04_Modele_Collaboratif.ipynb
```

### 6. Optimisation des hyperparamÃ¨tres
```bash
jupyter notebook 05_Optimisation_Hyperparametres.ipynb
```

## ğŸ“‚ Structure du Projet

```
hm-fashion-recommendation-pipeline/
â”‚
â”œâ”€â”€ ğŸ““ Notebooks
â”‚   â”œâ”€â”€ 00_setup_and_data_loading.ipynb     # Configuration et chargement
â”‚   â”œâ”€â”€ 01_Exploration_Donnees.ipynb        # Analyse exploratoire
â”‚   â”œâ”€â”€ 02_Echantillonnage_Donnees.ipynb    # StratÃ©gies d'Ã©chantillonnage
â”‚   â”œâ”€â”€ 03_Preparation_Donnees.ipynb        # Preprocessing des donnÃ©es
â”‚   â”œâ”€â”€ 04_Modele_Collaboratif.ipynb        # ModÃ©lisation LightFM
â”‚   â””â”€â”€ 05_Optimisation_Hyperparametres.ipynb # Tuning des paramÃ¨tres
â”‚
â”œâ”€â”€ ğŸ“ data/                                 # DonnÃ©es brutes et traitÃ©es
â”‚   â”œâ”€â”€ raw/                                # DonnÃ©es originales H&M
â”‚   â”œâ”€â”€ processed/                          # DonnÃ©es preprocessÃ©es
â”‚   â””â”€â”€ samples/                            # Ã‰chantillons pour dÃ©veloppement
â”‚
â”œâ”€â”€ ğŸ“ outputs/                             # RÃ©sultats et artefacts
â”‚   â”œâ”€â”€ figures/                            # Visualisations
â”‚   â”œâ”€â”€ models/                             # ModÃ¨les entraÃ®nÃ©s
â”‚   â””â”€â”€ results/                            # MÃ©triques et rapports
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt                      # DÃ©pendances Python
â””â”€â”€ ğŸ“– README.md                            # Documentation
```

## ğŸ”¬ MÃ©thodologie

### 1. Exploration des DonnÃ©es
- **Analyse de distribution** : Patterns d'achat, saisonnalitÃ©
- **Profiling utilisateurs** : Segmentation par comportement
- **Analyse de sparsitÃ©** : Identification des dÃ©fis du cold start

### 2. Ã‰chantillonnage StratÃ©gique
- **Utilisateurs actifs** : Focus sur clients avec historique suffisant
- **Articles populaires** : Concentration sur produits avec interactions
- **Ã‰chantillonnage temporel** : PrÃ©servation des tendances saisonniÃ¨res

### 3. Preprocessing
- **Encodage des identifiants** : Mapping vers entiers consÃ©cutifs
- **Feature engineering** : Extraction de mÃ©tadonnÃ©es produits
- **Matrix sparse** : Optimisation mÃ©moire pour interactions

### 4. ModÃ©lisation
- **LightFM** : ModÃ¨le hybride collaboratif + contenu
- **Loss functions** : WARP, BPR pour ranking
- **Embeddings** : ReprÃ©sentations latentes utilisateurs/articles

### 5. Ã‰valuation
- **Split temporel** : Train/validation respectant chronologie
- **MÃ©triques** : Precision@K, Recall@K, AUC, MRR
- **Cold start** : Ã‰valuation spÃ©cifique nouveaux utilisateurs/articles

## ğŸ“ˆ RÃ©sultats

### MÃ©triques de Performance
| MÃ©trique | Valeur |
|----------|--------|
| Precision@10 | 0.XX |
| Recall@10 | 0.XX |
| AUC | 0.XX |
| MRR | 0.XX |

### Insights ClÃ©s
- âœ… **SaisonnalitÃ© forte** : Pics d'activitÃ© pendant les soldes
- âœ… **Segmentation claire** : Comportements distincts par Ã¢ge/rÃ©gion
- âœ… **Long tail** : 80% des ventes sur 20% des articles
- âœ… **Cold start** : Challenge majeur pour nouveaux utilisateurs

## ğŸ”§ Configuration Google Colab

Pour utiliser ce projet sur Google Colab :

1. **Montage Google Drive**
```python
from google.colab import drive
drive.mount('/content/drive')
```

2. **Configuration des chemins**
```python
BASE_PATH = "/content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys"
DATA_PATH = f"{BASE_PATH}/data"
OUTPUTS_PATH = f"{BASE_PATH}/outputs"
```

3. **Installation des dÃ©pendances**
```python
!pip install lightfm tqdm
```

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Pour contribuer :

1. **Fork** le projet
2. **CrÃ©er** une branche feature (`git checkout -b feature/AmazingFeature`)
3. **Commit** vos changements (`git commit -m 'Add some AmazingFeature'`)
4. **Push** vers la branche (`git push origin feature/AmazingFeature`)
5. **Ouvrir** une Pull Request

## ğŸ“ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ‘¥ Auteurs

- **Votre Nom** - *DÃ©veloppement initial* - [@realnribal](https://github.com/realnribal)

## ğŸ™ Remerciements

- Dataset H&M Personalized Fashion Recommendations
- Ã‰quipe LightFM pour l'excellent framework
- CommunautÃ© Kaggle pour les insights et discussions

---

**â­ Si ce projet vous a Ã©tÃ© utile, n'hÃ©sitez pas Ã  lui donner une Ã©toile !**