{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "G6jnAxdkCBuv",
        "U4CJ2BI5CxEF",
        "n8A2rmyQDBfr",
        "A93ZcKEQDUcA",
        "ysa8DIzBDlNe",
        "kItbPEXaDwQ9",
        "zW_6uYlhD8Hz"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# H&M Fashion Recommendation Pipeline\n",
        "\n",
        "Ce notebook impl√©mente un pipeline de recommandation pour les donn√©es de mode H&M en utilisant LightFM. Il comprend le chargement des donn√©es, le pr√©traitement, le filtrage collaboratif, l'optimisation des hyperparam√®tres et un mod√®le hybride int√©grant des caract√©ristiques d'articles. Le pipeline √©value les performances du mod√®le et fournit un objet syst√®me de recommandation final pour faire des pr√©dictions."
      ],
      "metadata": {
        "id": "I5t57G7ABJhz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. CELLULE DE CONFIGURATION - MODIFIEZ UNIQUEMENT CETTE SECTION"
      ],
      "metadata": {
        "id": "G6jnAxdkCBuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "QUICK_TEST_MODE = True  # True pour test rapide, False pour run complet\n",
        "\n",
        "# Chemin de base vers vos donn√©es (MODIFIEZ CETTE LIGNE)\n",
        "USER_BASE_PATH = \"/content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys\"\n",
        "\n",
        "# Nom du dossier contenant les fichiers CSV (modifiez si diff√©rent)\n",
        "USER_DATA_FOLDER = \"data\"\n",
        "\n",
        "# Cr√©er un dossier unique pour chaque ex√©cution ?\n",
        "CREATE_TIMESTAMPED_OUTPUT = True\n",
        "\n",
        "# ========================================\n",
        "# PARAM√àTRES AVANC√âS (OPTIONNEL)\n",
        "# ========================================\n",
        "\n",
        "# √âchantillonnage (mode rapide)\n",
        "USER_QUICK_MAX_USERS = 1000\n",
        "USER_QUICK_MAX_ARTICLES = 500\n",
        "USER_QUICK_MIN_TRANSACTIONS = 10\n",
        "USER_QUICK_MIN_PURCHASES = 50\n",
        "USER_QUICK_EPOCHS_COLLABORATIVE = 2\n",
        "USER_QUICK_EPOCHS_HYBRID = 5\n",
        "\n",
        "# √âchantillonnage (mode complet) - None = toutes les donn√©es\n",
        "USER_FULL_MAX_USERS = None\n",
        "USER_FULL_MAX_ARTICLES = None\n",
        "USER_FULL_MIN_TRANSACTIONS = 5\n",
        "USER_FULL_MIN_PURCHASES = 10\n",
        "USER_FULL_EPOCHS_COLLABORATIVE = 5\n",
        "USER_FULL_EPOCHS_HYBRID = 50\n",
        "\n",
        "# Features articles √† utiliser (ajoutez/supprimez selon vos donn√©es)\n",
        "USER_ARTICLE_FEATURES = ['product_type_name', 'product_group_name', 'colour_group_name']\n",
        "\n",
        "# Loss functions √† tester\n",
        "USER_LOSS_FUNCTIONS = ['warp', 'bpr']  # Ajoutez 'logistic'\n",
        "\n",
        "# Grille hyperparam√®tres (mode rapide)\n",
        "USER_QUICK_PARAM_GRID = {\n",
        "    'no_components': [64, 128],\n",
        "    'learning_rate': [0.05, 0.1],\n",
        "    'item_alpha': [1e-5, 1e-4],\n",
        "    'user_alpha': [1e-5, 1e-4]\n",
        "}\n",
        "\n",
        "# Grille hyperparam√®tres (mode complet)\n",
        "USER_FULL_PARAM_GRID = {\n",
        "    'no_components': [64, 128, 256],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'item_alpha': [0.0, 1e-6, 1e-5, 1e-4],\n",
        "    'user_alpha': [0.0, 1e-6, 1e-5, 1e-4]\n",
        "}\n",
        "\n",
        "# ========================================\n",
        "# üîß CONFIGURATION AUTOMATIQUE (NE PAS MODIFIER)\n",
        "# ========================================\n",
        "\n",
        "# Application automatique des param√®tres selon le mode\n",
        "if QUICK_TEST_MODE:\n",
        "    print(\"üöÄ MODE TEST RAPIDE ACTIV√â\")\n",
        "    print(\"üìù √âchantillons r√©duits et moins d'epochs pour validation rapide\")\n",
        "    MAX_USERS = USER_QUICK_MAX_USERS\n",
        "    MAX_ARTICLES = USER_QUICK_MAX_ARTICLES\n",
        "    EPOCHS_COLLABORATIVE = USER_QUICK_EPOCHS_COLLABORATIVE\n",
        "    EPOCHS_HYBRID = USER_QUICK_EPOCHS_HYBRID\n",
        "    MIN_TRANSACTIONS = USER_QUICK_MIN_TRANSACTIONS\n",
        "    MIN_PURCHASES = USER_QUICK_MIN_PURCHASES\n",
        "    PARAM_GRID = USER_QUICK_PARAM_GRID\n",
        "else:\n",
        "    print(\"üêå MODE COMPLET ACTIV√â\")\n",
        "    MAX_USERS = USER_FULL_MAX_USERS\n",
        "    MAX_ARTICLES = USER_FULL_MAX_ARTICLES\n",
        "    EPOCHS_COLLABORATIVE = USER_FULL_EPOCHS_COLLABORATIVE\n",
        "    EPOCHS_HYBRID = USER_FULL_EPOCHS_HYBRID\n",
        "    MIN_TRANSACTIONS = USER_FULL_MIN_TRANSACTIONS\n",
        "    MIN_PURCHASES = USER_FULL_MIN_PURCHASES\n",
        "    PARAM_GRID = USER_FULL_PARAM_GRID\n",
        "\n",
        "# Configuration des chemins\n",
        "BASE_PATH = USER_BASE_PATH\n",
        "DATA_PATH = f\"{BASE_PATH}/{USER_DATA_FOLDER}\"\n",
        "ARTICLE_FEATURES = USER_ARTICLE_FEATURES\n",
        "LOSS_FUNCTIONS = USER_LOSS_FUNCTIONS\n",
        "\n",
        "print(\"üõçÔ∏è PIPELINE COMPLET DE RECOMMANDATION H&M FASHION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"üìÇ Chemin donn√©es: {DATA_PATH}\")\n",
        "print(f\"üë• Max utilisateurs: {MAX_USERS}\")\n",
        "print(f\"üéΩ Max articles: {MAX_ARTICLES}\")\n",
        "print(f\"üè∑Ô∏è Features: {len(ARTICLE_FEATURES)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82gCNPaaCmFs",
        "outputId": "5dea7f02-510d-48f5-bf9f-8ae7a4fc76d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ MODE TEST RAPIDE ACTIV√â\n",
            "üìù √âchantillons r√©duits et moins d'epochs pour validation rapide\n",
            "üõçÔ∏è PIPELINE COMPLET DE RECOMMANDATION H&M FASHION\n",
            "============================================================\n",
            "üìÇ Chemin donn√©es: /content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys/data\n",
            "üë• Max utilisateurs: 1000\n",
            "üéΩ Max articles: 500\n",
            "üè∑Ô∏è Features: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. CONFIGURATION ET SETUP"
      ],
      "metadata": {
        "id": "U4CJ2BI5CxEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüìó 1. CONFIGURATION ET SETUP\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "print(\"üîó Connexion √† Google Drive...\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"‚úÖ Google Drive mont√© avec succ√®s\")\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"\\nüóÇ Configuration des chemins de travail...\")\n",
        "\n",
        "# Cr√©ation d'un r√©pertoire unique pour chaque ex√©cution (MODIFI√â)\n",
        "if CREATE_TIMESTAMPED_OUTPUT:\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    run_id = f\"run_{timestamp}\"\n",
        "    OUTPUTS_PATH = f\"{BASE_PATH}/outputs/{run_id}\"\n",
        "else:\n",
        "    OUTPUTS_PATH = f\"{BASE_PATH}/outputs\"\n",
        "\n",
        "# Cr√©ation du r√©pertoire de sortie\n",
        "os.makedirs(OUTPUTS_PATH, exist_ok=True)\n",
        "\n",
        "print(f\"üìÇ Chemin de base : {BASE_PATH}\")\n",
        "print(f\"üìÇ Donn√©es : {DATA_PATH}\")\n",
        "print(f\"üìÇ Sorties : {OUTPUTS_PATH}\")\n",
        "if CREATE_TIMESTAMPED_OUTPUT:\n",
        "    print(f\"üÜî ID d'ex√©cution : {run_id}\")\n",
        "\n",
        "# Cr√©ation d'un fichier de log pour cette ex√©cution\n",
        "log_file = f\"{OUTPUTS_PATH}/execution_log.txt\"\n",
        "with open(log_file, 'w') as f:\n",
        "    f.write(f\"Ex√©cution du pipeline H&M Fashion Recommendation\\n\")\n",
        "    f.write(f\"Date/Heure: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "    f.write(f\"Mode: {'TEST RAPIDE' if QUICK_TEST_MODE else 'COMPLET'}\\n\")\n",
        "    f.write(f\"R√©pertoire: {OUTPUTS_PATH}\\n\")\n",
        "    f.write(f\"Param√®tres utilisateur appliqu√©s:\\n\")\n",
        "    f.write(f\"  - BASE_PATH: {BASE_PATH}\\n\")\n",
        "    f.write(f\"  - MAX_USERS: {MAX_USERS}\\n\")\n",
        "    f.write(f\"  - MAX_ARTICLES: {MAX_ARTICLES}\\n\")\n",
        "    f.write(f\"  - EPOCHS_COLLABORATIVE: {EPOCHS_COLLABORATIVE}\\n\")\n",
        "    f.write(f\"  - EPOCHS_HYBRID: {EPOCHS_HYBRID}\\n\")\n",
        "    f.write(\"=\"*50 + \"\\n\\n\")\n",
        "\n",
        "print(f\"üìù Log d'ex√©cution cr√©√© : {log_file}\")\n",
        "\n",
        "print(\"\\nüì¶ Installation des biblioth√®ques...\")\n",
        "!pip install git+https://github.com/daviddavo/lightfm -q\n",
        "!pip install -q tqdm\n",
        "\n",
        "# Imports\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from scipy.sparse import coo_matrix, csr_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
        "from lightfm import LightFM\n",
        "from lightfm.data import Dataset\n",
        "from lightfm.evaluation import precision_at_k, recall_at_k, auc_score\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"‚úÖ Configuration termin√©e\")\n",
        "\n",
        "# Fonction utilitaire pour logguer les √©tapes importantes\n",
        "def log_step(step_name, details=\"\"):\n",
        "    \"\"\"Log une √©tape dans le fichier de log\"\"\"\n",
        "    timestamp = datetime.now().strftime('%H:%M:%S')\n",
        "    with open(log_file, 'a') as f:\n",
        "        f.write(f\"[{timestamp}] {step_name}\\n\")\n",
        "        if details:\n",
        "            f.write(f\"  {details}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "    print(f\"üìù √âtape logg√©e: {step_name}\")\n",
        "\n",
        "log_step(\"Configuration termin√©e\", f\"R√©pertoire de sortie: {OUTPUTS_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1eAsHfDC2Qu",
        "outputId": "dd025eb9-48a5-4098-9369-2001fe67197f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìó 1. CONFIGURATION ET SETUP\n",
            "------------------------------\n",
            "üîó Connexion √† Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Google Drive mont√© avec succ√®s\n",
            "\n",
            "üóÇ Configuration des chemins de travail...\n",
            "üìÇ Chemin de base : /content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys\n",
            "üìÇ Donn√©es : /content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys/data\n",
            "üìÇ Sorties : /content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys/outputs/run_20250928_113619\n",
            "üÜî ID d'ex√©cution : run_20250928_113619\n",
            "üìù Log d'ex√©cution cr√©√© : /content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys/outputs/run_20250928_113619/execution_log.txt\n",
            "\n",
            "üì¶ Installation des biblioth√®ques...\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "‚úÖ Configuration termin√©e\n",
            "üìù √âtape logg√©e: Configuration termin√©e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. CHARGEMENT DES DONN√âES"
      ],
      "metadata": {
        "id": "n8A2rmyQDBfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüìä 2. CHARGEMENT DES DONN√âES\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "files_to_check = [\n",
        "    f\"{DATA_PATH}/transactions_train.csv\",\n",
        "    f\"{DATA_PATH}/customers.csv\",\n",
        "    f\"{DATA_PATH}/articles.csv\"\n",
        "]\n",
        "\n",
        "for file_path in files_to_check:\n",
        "    if os.path.exists(file_path):\n",
        "        size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
        "        print(f\"‚úÖ {os.path.basename(file_path)}: {size_mb:.1f} MB\")\n",
        "    else:\n",
        "        print(f\"‚ùå Fichier manquant: {os.path.basename(file_path)}\")\n",
        "\n",
        "print(\"\\n‚è≥ Chargement en cours...\")\n",
        "\n",
        "try:\n",
        "    transactions = pd.read_csv(f\"{DATA_PATH}/transactions_train.csv\")\n",
        "    customers = pd.read_csv(f\"{DATA_PATH}/customers.csv\")\n",
        "    articles = pd.read_csv(f\"{DATA_PATH}/articles.csv\")\n",
        "\n",
        "    print(f\"üìà Transactions: {len(transactions):,} lignes\")\n",
        "    print(f\"üë• Clients: {len(customers):,} lignes\")\n",
        "    print(f\"üëï Articles: {len(articles):,} lignes\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"‚ùå Erreur de chargement: {e}\")\n",
        "    print(f\"üîç V√©rifiez que le chemin est correct: {DATA_PATH}\")\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIHsfsTkDFv2",
        "outputId": "1f29ad5a-4741-4956-cf4d-a49a291e6bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä 2. CHARGEMENT DES DONN√âES\n",
            "------------------------------\n",
            "‚úÖ transactions_train.csv: 3326.4 MB\n",
            "‚úÖ customers.csv: 197.5 MB\n",
            "‚úÖ articles.csv: 34.5 MB\n",
            "\n",
            "‚è≥ Chargement en cours...\n",
            "üìà Transactions: 31,788,324 lignes\n",
            "üë• Clients: 1,371,980 lignes\n",
            "üëï Articles: 105,542 lignes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. EXPLORATION RAPIDE DES DONN√âES"
      ],
      "metadata": {
        "id": "Gz4piYkaDKXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 3. EXPLORATION RAPIDE DES DONN√âES\n",
        "# =============================================================================\n",
        "print(\"\\nüîç 3. EXPLORATION RAPIDE DES DONN√âES\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Informations g√©n√©rales\n",
        "print(f\"üìä P√©riode des transactions: {transactions['t_dat'].min()} √† {transactions['t_dat'].max()}\")\n",
        "print(f\"üë• Clients uniques: {transactions['customer_id'].nunique():,}\")\n",
        "print(f\"üëï Articles uniques: {transactions['article_id'].nunique():,}\")\n",
        "print(f\"üí∞ Prix m√©dian: {transactions['price'].median():.2f}\")\n",
        "\n",
        "# Conversion de dates\n",
        "transactions['t_dat'] = pd.to_datetime(transactions['t_dat'])\n",
        "\n",
        "# =============================================================================\n",
        "# 4. √âCHANTILLONNAGE STRAT√âGIQUE OPTIMIS√â\n",
        "# =============================================================================\n",
        "print(\"\\nüéØ 4. √âCHANTILLONNAGE STRAT√âGIQUE\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Analyse de l'activit√© des utilisateurs\n",
        "user_activity = transactions.groupby('customer_id').size().sort_values(ascending=False)\n",
        "print(f\"üë• Clients uniques: {len(user_activity):,}\")\n",
        "print(f\"üìä Transactions par client - M√©diane: {user_activity.median():.0f}\")\n",
        "\n",
        "# Clients actifs (configuration optimis√©e)\n",
        "active_users = user_activity[user_activity >= MIN_TRANSACTIONS].index\n",
        "if QUICK_TEST_MODE and len(active_users) > MAX_USERS:\n",
        "    active_users = active_users[:MAX_USERS]\n",
        "\n",
        "# Articles populaires\n",
        "article_popularity = transactions.groupby('article_id').size().sort_values(ascending=False)\n",
        "popular_articles = article_popularity[article_popularity >= MIN_PURCHASES].index\n",
        "if QUICK_TEST_MODE and len(popular_articles) > MAX_ARTICLES:\n",
        "    popular_articles = popular_articles[:MAX_ARTICLES]\n",
        "\n",
        "print(f\"üî• Clients actifs s√©lectionn√©s: {len(active_users):,}\")\n",
        "print(f\"üìà Articles populaires s√©lectionn√©s: {len(popular_articles):,}\")\n",
        "\n",
        "# Cr√©ation de l'√©chantillon\n",
        "sample_transactions = transactions[\n",
        "    (transactions['customer_id'].isin(active_users)) &\n",
        "    (transactions['article_id'].isin(popular_articles))\n",
        "].copy()\n",
        "\n",
        "print(f\"üìä √âchantillon cr√©√©: {len(sample_transactions):,} transactions\")\n",
        "print(f\"üë• Clients dans l'√©chantillon: {sample_transactions['customer_id'].nunique():,}\")\n",
        "print(f\"üëï Articles dans l'√©chantillon: {sample_transactions['article_id'].nunique():,}\")\n",
        "\n",
        "# Sauvegarde\n",
        "os.makedirs(OUTPUTS_PATH, exist_ok=True)\n",
        "sample_data = {\n",
        "    'transactions': sample_transactions,\n",
        "    'customers': customers[customers['customer_id'].isin(sample_transactions['customer_id'])],\n",
        "    'articles': articles[articles['article_id'].isin(sample_transactions['article_id'])]\n",
        "}\n",
        "\n",
        "sample_path = f\"{OUTPUTS_PATH}/sample_data.pkl\"\n",
        "with open(sample_path, 'wb') as f:\n",
        "    pickle.dump(sample_data, f)\n",
        "\n",
        "print(f\"üíæ √âchantillon sauvegard√©: {sample_path}\")\n",
        "log_step(\"√âchantillonnage termin√©\", f\"Transactions: {len(sample_transactions):,}, Users: {len(active_users):,}, Articles: {len(popular_articles):,}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgz1TDGpDR_I",
        "outputId": "b8b92832-6616-445f-cf03-1ead2d7aa92a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç 3. EXPLORATION RAPIDE DES DONN√âES\n",
            "------------------------------\n",
            "üìä P√©riode des transactions: 2018-09-20 √† 2020-09-22\n",
            "üë• Clients uniques: 1,362,281\n",
            "üëï Articles uniques: 104,547\n",
            "üí∞ Prix m√©dian: 0.03\n",
            "\n",
            "üéØ 4. √âCHANTILLONNAGE STRAT√âGIQUE\n",
            "------------------------------\n",
            "üë• Clients uniques: 1,362,281\n",
            "üìä Transactions par client - M√©diane: 9\n",
            "üî• Clients actifs s√©lectionn√©s: 1,000\n",
            "üìà Articles populaires s√©lectionn√©s: 500\n",
            "üìä √âchantillon cr√©√©: 41,850 transactions\n",
            "üë• Clients dans l'√©chantillon: 998\n",
            "üëï Articles dans l'√©chantillon: 500\n",
            "üíæ √âchantillon sauvegard√©: /content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys/outputs/run_20250928_113619/sample_data.pkl\n",
            "üìù √âtape logg√©e: √âchantillonnage termin√©\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. PR√âPARATION DES DONN√âES\n"
      ],
      "metadata": {
        "id": "A93ZcKEQDUcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüîß 5. PR√âPARATION DES DONN√âES\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# R√©cup√©ration des donn√©es √©chantillonn√©es\n",
        "transactions_sample = sample_data['transactions']\n",
        "customers_sample = sample_data['customers']\n",
        "articles_sample = sample_data['articles']\n",
        "\n",
        "# Encodage des IDs\n",
        "user_encoder = LabelEncoder()\n",
        "item_encoder = LabelEncoder()\n",
        "\n",
        "transactions_sample['user_id'] = user_encoder.fit_transform(transactions_sample['customer_id'])\n",
        "transactions_sample['item_id'] = item_encoder.fit_transform(transactions_sample['article_id'])\n",
        "\n",
        "num_users = len(user_encoder.classes_)\n",
        "num_items = len(item_encoder.classes_)\n",
        "\n",
        "print(f\"üë• Utilisateurs encod√©s: {num_users:,}\")\n",
        "print(f\"üëï Articles encod√©s: {num_items:,}\")\n",
        "\n",
        "# Split temporel train/test avec s√©paration stricte des interactions\n",
        "split_date = transactions_sample['t_dat'].quantile(0.8)\n",
        "train_transactions = transactions_sample[transactions_sample['t_dat'] <= split_date]\n",
        "test_transactions = transactions_sample[transactions_sample['t_dat'] > split_date]\n",
        "\n",
        "print(f\"üìÖ Date de split: {split_date}\")\n",
        "print(f\"üöÇ Train: {len(train_transactions):,} transactions\")\n",
        "print(f\"üß™ Test: {len(test_transactions):,} transactions\")\n",
        "\n",
        "# Cr√©ation des matrices train/test\n",
        "train_matrix = csr_matrix(\n",
        "    (np.ones(len(train_transactions)),\n",
        "     (train_transactions['user_id'], train_transactions['item_id'])),\n",
        "    shape=(num_users, num_items)\n",
        ")\n",
        "\n",
        "# Pour le test, on ne garde que les nouvelles interactions (pas dans train)\n",
        "# Cr√©er un set des interactions d'entra√Ænement\n",
        "train_interactions_set = set(zip(train_transactions['user_id'], train_transactions['item_id']))\n",
        "\n",
        "# Filtrer les interactions de test pour exclure celles d√©j√† dans train\n",
        "test_filtered = []\n",
        "for _, row in test_transactions.iterrows():\n",
        "    user_item_pair = (row['user_id'], row['item_id'])\n",
        "    if user_item_pair not in train_interactions_set:\n",
        "        test_filtered.append(row)\n",
        "\n",
        "if test_filtered:\n",
        "    test_df = pd.DataFrame(test_filtered)\n",
        "    test_matrix = csr_matrix(\n",
        "        (np.ones(len(test_df)),\n",
        "         (test_df['user_id'], test_df['item_id'])),\n",
        "        shape=(num_users, num_items)\n",
        "    )\n",
        "    print(f\"üîç Interactions test filtr√©es: {len(test_df):,} (nouvelles interactions uniquement)\")\n",
        "else:\n",
        "    # Si pas d'interactions nouvelles, cr√©er un split utilisateur diff√©rent\n",
        "    print(\"‚ö†Ô∏è  Pas de nouvelles interactions dans le test temporel, utilisation d'un split utilisateur...\")\n",
        "\n",
        "    # Split par utilisateur (80/20)\n",
        "    unique_users = transactions_sample['user_id'].unique()\n",
        "    np.random.seed(42)\n",
        "    np.random.shuffle(unique_users)\n",
        "\n",
        "    n_train_users = int(0.8 * len(unique_users))\n",
        "    train_users = unique_users[:n_train_users]\n",
        "    test_users = unique_users[n_train_users:]\n",
        "\n",
        "    train_transactions = transactions_sample[transactions_sample['user_id'].isin(train_users)]\n",
        "    test_transactions = transactions_sample[transactions_sample['user_id'].isin(test_users)]\n",
        "\n",
        "    train_matrix = csr_matrix(\n",
        "        (np.ones(len(train_transactions)),\n",
        "         (train_transactions['user_id'], train_transactions['item_id'])),\n",
        "        shape=(num_users, num_items)\n",
        "    )\n",
        "\n",
        "    test_matrix = csr_matrix(\n",
        "        (np.ones(len(test_transactions)),\n",
        "         (test_transactions['user_id'], test_transactions['item_id'])),\n",
        "        shape=(num_users, num_items)\n",
        "    )\n",
        "\n",
        "    print(f\"üöÇ Train (utilisateurs): {len(train_transactions):,} transactions, {len(train_users):,} utilisateurs\")\n",
        "    print(f\"üß™ Test (utilisateurs): {len(test_transactions):,} transactions, {len(test_users):,} utilisateurs\")\n",
        "\n",
        "print(f\"üìä Matrice train: {train_matrix.shape} - Interactions: {train_matrix.nnz:,}\")\n",
        "print(f\"üìä Matrice test: {test_matrix.shape} - Interactions: {test_matrix.nnz:,}\")\n",
        "print(f\"üìä Densit√© train: {train_matrix.nnz / (train_matrix.shape[0] * train_matrix.shape[1]):.6f}\")\n",
        "print(f\"üìä Densit√© test: {test_matrix.nnz / (test_matrix.shape[0] * test_matrix.shape[1]):.6f}\")\n",
        "\n",
        "# V√©rification qu'il n'y a pas d'interactions communes\n",
        "common_interactions = train_matrix.multiply(test_matrix).nnz\n",
        "print(f\"üîç Interactions communes (doit √™tre 0): {common_interactions}\")\n",
        "\n",
        "if common_interactions > 0:\n",
        "    print(\"‚ö†Ô∏è  ATTENTION: Il y a encore des interactions communes!\")\n",
        "    print(\"üîß Application d'un nettoyage suppl√©mentaire...\")\n",
        "\n",
        "    # M√©thode alternative: masquer les interactions communes dans test\n",
        "    test_matrix_clean = test_matrix.copy()\n",
        "    test_matrix_clean[train_matrix.nonzero()] = 0\n",
        "    test_matrix_clean.eliminate_zeros()\n",
        "    test_matrix = test_matrix_clean\n",
        "\n",
        "    print(f\"‚úÖ Test nettoy√©: {test_matrix.nnz:,} interactions\")\n",
        "    print(f\"üîç Interactions communes apr√®s nettoyage: {train_matrix.multiply(test_matrix).nnz}\")\n",
        "\n",
        "assert train_matrix.multiply(test_matrix).nnz == 0, \"Erreur: interactions communes d√©tect√©es!\"\n",
        "print(\"‚úÖ Validation: Aucune interaction commune entre train et test\")\n",
        "\n",
        "# Sauvegarde\n",
        "prepared_data = {\n",
        "    'train_matrix': train_matrix,\n",
        "    'test_matrix': test_matrix,\n",
        "    'user_encoder': user_encoder,\n",
        "    'item_encoder': item_encoder,\n",
        "    'transactions_sample': transactions_sample,\n",
        "    'train_transactions': train_transactions,\n",
        "    'test_transactions': test_transactions\n",
        "}\n",
        "\n",
        "prepared_path = f\"{OUTPUTS_PATH}/prepared_data.pkl\"\n",
        "with open(prepared_path, 'wb') as f:\n",
        "    pickle.dump(prepared_data, f)\n",
        "\n",
        "print(f\"üíæ Donn√©es pr√©par√©es sauvegard√©es\")\n",
        "log_step(\"Pr√©paration donn√©es termin√©e\", f\"Train: {train_matrix.nnz:,} interactions, Test: {test_matrix.nnz:,} interactions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWhwJ-MtDeFx",
        "outputId": "892c6fea-58a6-482e-c710-ea2b02710f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîß 5. PR√âPARATION DES DONN√âES\n",
            "------------------------------\n",
            "üë• Utilisateurs encod√©s: 998\n",
            "üëï Articles encod√©s: 500\n",
            "üìÖ Date de split: 2020-04-04 00:00:00\n",
            "üöÇ Train: 33,627 transactions\n",
            "üß™ Test: 8,223 transactions\n",
            "üîç Interactions test filtr√©es: 6,781 (nouvelles interactions uniquement)\n",
            "üìä Matrice train: (998, 500) - Interactions: 19,996\n",
            "üìä Matrice test: (998, 500) - Interactions: 4,588\n",
            "üìä Densit√© train: 0.040072\n",
            "üìä Densit√© test: 0.009194\n",
            "üîç Interactions communes (doit √™tre 0): 0\n",
            "‚úÖ Validation: Aucune interaction commune entre train et test\n",
            "üíæ Donn√©es pr√©par√©es sauvegard√©es\n",
            "üìù √âtape logg√©e: Pr√©paration donn√©es termin√©e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. MOD√àLE COLLABORATIF\n"
      ],
      "metadata": {
        "id": "ysa8DIzBDlNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nü§ù 6. MOD√àLE COLLABORATIF\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Test de diff√©rentes loss functions (MODIFI√â pour utiliser LOSS_FUNCTIONS)\n",
        "loss_functions = LOSS_FUNCTIONS\n",
        "models = {}\n",
        "results = {}\n",
        "\n",
        "for loss in loss_functions:\n",
        "    print(f\"\\nüîÑ Entra√Ænement avec {loss.upper()}...\")\n",
        "\n",
        "    model = LightFM(loss=loss, random_state=42)\n",
        "    model.fit(train_matrix, epochs=EPOCHS_COLLABORATIVE, num_threads=2, verbose=True)\n",
        "\n",
        "    # √âvaluation\n",
        "    train_auc = auc_score(model, train_matrix).mean()\n",
        "    test_auc = auc_score(model, test_matrix, train_interactions=train_matrix).mean()\n",
        "    test_precision = precision_at_k(model, test_matrix, train_interactions=train_matrix, k=10).mean()\n",
        "\n",
        "    results[loss] = {\n",
        "        'train_auc': train_auc,\n",
        "        'test_auc': test_auc,\n",
        "        'test_precision': test_precision\n",
        "    }\n",
        "    models[loss] = model\n",
        "\n",
        "    print(f\"‚úÖ {loss.upper()} - AUC Test: {test_auc:.4f}, Precision@10: {test_precision:.4f}\")\n",
        "\n",
        "# S√©lection du meilleur mod√®le\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(f\"\\nüìä COMPARAISON DES MOD√àLES:\")\n",
        "print(results_df)\n",
        "\n",
        "best_loss = results_df['test_auc'].idxmax()\n",
        "best_model = models[best_loss]\n",
        "best_score = results_df.loc[best_loss, 'test_auc']\n",
        "\n",
        "print(f\"\\nüèÜ Meilleur mod√®le: {best_loss.upper()} (AUC: {best_score:.4f})\")\n",
        "log_step(\"Mod√®le collaboratif termin√©\", f\"Meilleur: {best_loss.upper()}, AUC: {best_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn0HWlnfDo9r",
        "outputId": "c6f9ddbe-86d7-457e-ddbf-c0d06872efd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü§ù 6. MOD√àLE COLLABORATIF\n",
            "------------------------------\n",
            "\n",
            "üîÑ Entra√Ænement avec WARP...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  4.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ WARP - AUC Test: 0.4585, Precision@10: 0.0139\n",
            "\n",
            "üîÑ Entra√Ænement avec BPR...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  4.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ BPR - AUC Test: 0.4973, Precision@10: 0.0096\n",
            "\n",
            "üìä COMPARAISON DES MOD√àLES:\n",
            "      train_auc  test_auc  test_precision\n",
            "warp   0.656556  0.458495        0.013901\n",
            "bpr    0.541479  0.497327        0.009641\n",
            "\n",
            "üèÜ Meilleur mod√®le: BPR (AUC: 0.4973)\n",
            "üìù √âtape logg√©e: Mod√®le collaboratif termin√©\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. OPTIMISATION DES HYPERPARAM√àTRES (RAPIDE)\n"
      ],
      "metadata": {
        "id": "kItbPEXaDwQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüîß 7. OPTIMISATION DES HYPERPARAM√àTRES\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Grille r√©duite pour test rapide (MODIFI√â pour utiliser PARAM_GRID)\n",
        "param_grid = PARAM_GRID\n",
        "\n",
        "print(f\"üîç Test de {np.prod([len(v) for v in param_grid.values()])} combinaisons...\")\n",
        "\n",
        "best_optimized_score = 0\n",
        "best_params = {}\n",
        "optimization_count = 0\n",
        "\n",
        "for no_components in param_grid['no_components']:\n",
        "    for learning_rate in param_grid['learning_rate']:\n",
        "        for item_alpha in param_grid['item_alpha']:\n",
        "            for user_alpha in param_grid['user_alpha']:\n",
        "                optimization_count += 1\n",
        "\n",
        "                params = {\n",
        "                    'no_components': no_components,\n",
        "                    'learning_rate': learning_rate,\n",
        "                    'item_alpha': item_alpha,\n",
        "                    'user_alpha': user_alpha\n",
        "                }\n",
        "\n",
        "                try:\n",
        "                    model = LightFM(\n",
        "                        loss=best_loss,\n",
        "                        no_components=no_components,\n",
        "                        learning_rate=learning_rate,\n",
        "                        item_alpha=item_alpha,\n",
        "                        user_alpha=user_alpha,\n",
        "                        random_state=42\n",
        "                    )\n",
        "\n",
        "                    model.fit(train_matrix, epochs=EPOCHS_COLLABORATIVE, num_threads=2)\n",
        "                    test_auc = auc_score(model, test_matrix, train_interactions=train_matrix).mean()\n",
        "\n",
        "                    if test_auc > best_optimized_score:\n",
        "                        best_optimized_score = test_auc\n",
        "                        best_params = params\n",
        "                        best_optimized_model = model\n",
        "\n",
        "                    print(f\"‚úì {optimization_count}/{np.prod([len(v) for v in param_grid.values()])} - Components: {no_components}, LR: {learning_rate}, AUC: {test_auc:.4f}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"‚úó Erreur avec {params}: {e}\")\n",
        "\n",
        "print(f\"\\nüèÜ MEILLEURS HYPERPARAM√àTRES:\")\n",
        "for param, value in best_params.items():\n",
        "    print(f\"  {param}: {value}\")\n",
        "print(f\"üéØ Meilleur score AUC: {best_optimized_score:.4f}\")\n",
        "log_step(\"Optimisation hyperparam√®tres termin√©e\", f\"Meilleur AUC: {best_optimized_score:.4f}, Params: {best_params}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zz1xeTiaD0eM",
        "outputId": "5820f39a-3eda-441d-86fd-186374d91356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîß 7. OPTIMISATION DES HYPERPARAM√àTRES\n",
            "------------------------------\n",
            "üîç Test de 16 combinaisons...\n",
            "‚úì 1/16 - Components: 64, LR: 0.05, AUC: 0.5207\n",
            "‚úì 2/16 - Components: 64, LR: 0.05, AUC: 0.5226\n",
            "‚úì 3/16 - Components: 64, LR: 0.05, AUC: 0.5231\n",
            "‚úì 4/16 - Components: 64, LR: 0.05, AUC: 0.5229\n",
            "‚úì 5/16 - Components: 64, LR: 0.1, AUC: 0.5278\n",
            "‚úì 6/16 - Components: 64, LR: 0.1, AUC: 0.5275\n",
            "‚úì 7/16 - Components: 64, LR: 0.1, AUC: 0.5310\n",
            "‚úì 8/16 - Components: 64, LR: 0.1, AUC: 0.5314\n",
            "‚úì 9/16 - Components: 128, LR: 0.05, AUC: 0.5201\n",
            "‚úì 10/16 - Components: 128, LR: 0.05, AUC: 0.5204\n",
            "‚úì 11/16 - Components: 128, LR: 0.05, AUC: 0.5204\n",
            "‚úì 12/16 - Components: 128, LR: 0.05, AUC: 0.5205\n",
            "‚úì 13/16 - Components: 128, LR: 0.1, AUC: 0.5186\n",
            "‚úì 14/16 - Components: 128, LR: 0.1, AUC: 0.5186\n",
            "‚úì 15/16 - Components: 128, LR: 0.1, AUC: 0.5188\n",
            "‚úì 16/16 - Components: 128, LR: 0.1, AUC: 0.5186\n",
            "\n",
            "üèÜ MEILLEURS HYPERPARAM√àTRES:\n",
            "  no_components: 64\n",
            "  learning_rate: 0.1\n",
            "  item_alpha: 0.0001\n",
            "  user_alpha: 0.0001\n",
            "üéØ Meilleur score AUC: 0.5314\n",
            "üìù √âtape logg√©e: Optimisation hyperparam√®tres termin√©e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. √âVALUATION COMPL√àTE\n"
      ],
      "metadata": {
        "id": "zW_6uYlhD8Hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüìä 8. √âVALUATION COMPL√àTE\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# √âvaluation sur diff√©rentes valeurs de k\n",
        "k_values = [5, 10, 20]\n",
        "evaluation_results = {}\n",
        "\n",
        "print(\"üìà M√âTRIQUES D'√âVALUATION\")\n",
        "for k in k_values:\n",
        "    precision_k = precision_at_k(best_optimized_model, test_matrix, train_interactions=train_matrix, k=k).mean()\n",
        "    recall_k = recall_at_k(best_optimized_model, test_matrix, train_interactions=train_matrix, k=k).mean()\n",
        "\n",
        "    evaluation_results[f'precision@{k}'] = precision_k\n",
        "    evaluation_results[f'recall@{k}'] = recall_k\n",
        "\n",
        "    print(f\"üìä Precision@{k}: {precision_k:.4f} | Recall@{k}: {recall_k:.4f}\")\n",
        "\n",
        "evaluation_results['auc'] = best_optimized_score\n",
        "print(f\"üìä AUC Score: {best_optimized_score:.4f}\")\n",
        "log_step(\"√âvaluation mod√®le termin√©e\", f\"AUC: {best_optimized_score:.4f}, Precision@10: {evaluation_results['precision@10']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc0Cp3nvEB0m",
        "outputId": "1a7e06ce-9d97-4eac-df15-e0cb9f90e426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä 8. √âVALUATION COMPL√àTE\n",
            "------------------------------\n",
            "üìà M√âTRIQUES D'√âVALUATION\n",
            "üìä Precision@5: 0.0099 | Recall@5: 0.0085\n",
            "üìä Precision@10: 0.0117 | Recall@10: 0.0190\n",
            "üìä Precision@20: 0.0158 | Recall@20: 0.0613\n",
            "üìä AUC Score: 0.5314\n",
            "üìù √âtape logg√©e: √âvaluation mod√®le termin√©e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. MOD√àLE HYBRIDE\n"
      ],
      "metadata": {
        "id": "OvMf2a04EFmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüîÄ 9. MOD√àLE HYBRIDE AVEC FEATURES\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "print(\"üè∑Ô∏è Pr√©paration des features d'articles...\")\n",
        "\n",
        "# S√©lection des features cat√©gorielles (MODIFI√â pour utiliser ARTICLE_FEATURES)\n",
        "feature_columns = [col for col in ARTICLE_FEATURES if col in articles_sample.columns]\n",
        "if not feature_columns:\n",
        "    print(f\"‚ùå Aucune feature disponible parmi: {ARTICLE_FEATURES}\")\n",
        "    print(f\"üìã Colonnes disponibles: {list(articles_sample.columns)}\")\n",
        "    # Utiliser des features par d√©faut si disponibles\n",
        "    fallback_features = ['product_type_name', 'product_group_name', 'colour_group_name']\n",
        "    feature_columns = [col for col in fallback_features if col in articles_sample.columns]\n",
        "    if feature_columns:\n",
        "        print(f\"üîÑ Utilisation des features par d√©faut: {feature_columns}\")\n",
        "    else:\n",
        "        print(\"‚ùå Aucune feature utilisable trouv√©e - utilisation du mod√®le collaboratif\")\n",
        "        hybrid_model = best_optimized_model\n",
        "        hybrid_auc = best_optimized_score\n",
        "        hybrid_precision = evaluation_results['precision@10']\n",
        "        feature_columns = []\n",
        "\n",
        "if feature_columns:\n",
        "    print(f\"‚úÖ Features utilis√©es: {feature_columns}\")\n",
        "\n",
        "    articles_features = articles_sample[['article_id'] + feature_columns].copy()\n",
        "\n",
        "    # Nettoyage des valeurs manquantes\n",
        "    for col in feature_columns:\n",
        "        articles_features[col] = articles_features[col].fillna('Unknown')\n",
        "\n",
        "    # Cr√©ation du dataset LightFM avec features\n",
        "    dataset = Dataset()\n",
        "\n",
        "    unique_users = transactions_sample['customer_id'].unique()\n",
        "    unique_items = transactions_sample['article_id'].unique()\n",
        "\n",
        "    # Pr√©paration des features d'items\n",
        "    item_features = []\n",
        "    for _, row in articles_features.iterrows():\n",
        "        features = [f\"{col}:{row[col]}\" for col in feature_columns]\n",
        "        item_features.append((row['article_id'], features))\n",
        "\n",
        "    dataset.fit(users=unique_users,\n",
        "               items=unique_items,\n",
        "               item_features=[f\"{col}:{val}\" for col in feature_columns\n",
        "                             for val in articles_features[col].unique()])\n",
        "\n",
        "    print(f\"üìä Dataset cr√©√© avec {len(unique_users):,} utilisateurs et {len(unique_items):,} articles\")\n",
        "\n",
        "    # Construction des matrices avec features\n",
        "    interactions_matrix, weights = dataset.build_interactions(\n",
        "        [(row['customer_id'], row['article_id']) for _, row in transactions_sample.iterrows()]\n",
        "    )\n",
        "\n",
        "    item_features_matrix = dataset.build_item_features(item_features)\n",
        "\n",
        "    print(f\"üìä Matrice d'interactions: {interactions_matrix.shape}\")\n",
        "    print(f\"üìä Matrice de features: {item_features_matrix.shape}\")\n",
        "\n",
        "    # Entra√Ænement du mod√®le hybride\n",
        "    print(f\"\\nüîÑ Entra√Ænement du mod√®le hybride ({EPOCHS_HYBRID} epochs)...\")\n",
        "\n",
        "    hybrid_model = LightFM(\n",
        "        loss=best_loss,\n",
        "        no_components=best_params.get('no_components', 128),\n",
        "        learning_rate=best_params.get('learning_rate', 0.05),\n",
        "        item_alpha=best_params.get('item_alpha', 1e-5),\n",
        "        user_alpha=best_params.get('user_alpha', 1e-5),\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    hybrid_model.fit(interactions_matrix,\n",
        "                    item_features=item_features_matrix,\n",
        "                    epochs=EPOCHS_HYBRID,\n",
        "                    num_threads=2,\n",
        "                    verbose=True)\n",
        "\n",
        "    # √âvaluation du mod√®le hybride\n",
        "    print(\"\\nüìä √âvaluation du mod√®le hybride...\")\n",
        "\n",
        "    hybrid_auc = auc_score(hybrid_model, interactions_matrix, item_features=item_features_matrix).mean()\n",
        "    hybrid_precision = precision_at_k(hybrid_model, interactions_matrix, item_features=item_features_matrix, k=10).mean()\n",
        "\n",
        "    print(f\"üéØ Mod√®le Hybride - AUC: {hybrid_auc:.4f}\")\n",
        "    print(f\"üéØ Mod√®le Hybride - Precision@10: {hybrid_precision:.4f}\")\n",
        "\n",
        "    # Comparaison\n",
        "    print(f\"\\nüìä COMPARAISON MOD√àLES:\")\n",
        "    print(f\"  Collaboratif - AUC: {best_optimized_score:.4f}\")\n",
        "    print(f\"  Hybride - AUC: {hybrid_auc:.4f}\")\n",
        "    improvement = ((hybrid_auc - best_optimized_score) / best_optimized_score * 100)\n",
        "    print(f\"  Am√©lioration: {improvement:+.2f}%\")\n",
        "    log_step(\"Mod√®le hybride termin√©\", f\"AUC Hybride: {hybrid_auc:.4f}, Am√©lioration: {improvement:+.2f}%\")\n",
        "\n",
        "else:\n",
        "    # Pas de features disponibles\n",
        "    hybrid_auc = best_optimized_score\n",
        "    hybrid_precision = evaluation_results['precision@10']\n",
        "    improvement = 0.0\n",
        "    print(\"üìä Utilisation du mod√®le collaboratif optimis√© comme mod√®le final\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8f8lF60EJze",
        "outputId": "aaaa280b-95ae-4381-d0ef-0d62341dd0e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÄ 9. MOD√àLE HYBRIDE AVEC FEATURES\n",
            "------------------------------\n",
            "üè∑Ô∏è Pr√©paration des features d'articles...\n",
            "‚úÖ Features utilis√©es: ['product_type_name', 'product_group_name', 'colour_group_name']\n",
            "üìä Dataset cr√©√© avec 998 utilisateurs et 500 articles\n",
            "üìä Matrice d'interactions: (998, 500)\n",
            "üìä Matrice de features: (500, 565)\n",
            "\n",
            "üîÑ Entra√Ænement du mod√®le hybride (5 epochs)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  2.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä √âvaluation du mod√®le hybride...\n",
            "üéØ Mod√®le Hybride - AUC: 0.7111\n",
            "üéØ Mod√®le Hybride - Precision@10: 0.1763\n",
            "\n",
            "üìä COMPARAISON MOD√àLES:\n",
            "  Collaboratif - AUC: 0.5314\n",
            "  Hybride - AUC: 0.7111\n",
            "  Am√©lioration: +33.80%\n",
            "üìù √âtape logg√©e: Mod√®le hybride termin√©\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. PIPELINE FINAL ET TESTS\n"
      ],
      "metadata": {
        "id": "3DS70HhmEN66"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xlefLA4_wTK",
        "outputId": "664d1b79-ba13-4122-a37d-d5bc6d8634bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ 10. PIPELINE FINAL ET TESTS\n",
            "------------------------------\n",
            "üîß Initialisation du syst√®me de recommandation...\n",
            "‚úÖ Syst√®me de recommandation hybride initialis√©\n",
            "\n",
            "üß™ TESTS DU SYST√àME DE RECOMMANDATION\n",
            "\n",
            "üë§ Recommandations pour le client 01e464bf74b13a55df22de1528eff2b33749c0cd92953b62bd22dee2de17d1fd:\n",
            "  1. Article 448509014 - Trousers (Blue) - Score: -0.553\n",
            "  2. Article 714790003 - Trousers (Blue) - Score: -0.595\n",
            "  3. Article 573085004 - Trousers (Blue) - Score: -0.597\n",
            "\n",
            "üë§ Recommandations pour le client 08ddd7be3e60252d2cba9dd55297a6ad0bdc1f4e244a16a8ebf61b73c56557c5:\n",
            "  1. Article 706016001 - Trousers (Black) - Score: 0.071\n",
            "  2. Article 562245046 - Trousers (Black) - Score: 0.070\n",
            "  3. Article 399201005 - Trousers (Dark Blue) - Score: 0.062\n",
            "\n",
            "üë§ Recommandations pour le client 0e1ca3cd38b0fd1727ef7cc963d8f5ac1f37617593d57f1b497ffa74b0937c2c:\n",
            "  1. Article 160442010 - Socks (White) - Score: -1.115\n",
            "  2. Article 372860002 - Socks (White) - Score: -1.126\n",
            "  3. Article 470789019 - Underwear bottom (Light Beige) - Score: -1.128\n",
            "\n",
            "üîç TEST SIMILARIT√â D'ARTICLES\n",
            "Erreur pour article 519583008: np.int64(533)\n",
            "Aucun article similaire trouv√©\n",
            "üìù √âtape logg√©e: Pipeline termin√© avec succ√®s\n",
            "\n",
            "============================================================\n",
            "üéâ PIPELINE TERMIN√â AVEC SUCC√àS !\n",
            "============================================================\n",
            "\n",
            "üìã CONFIGURATION UTILIS√âE:\n",
            "  üîß Mode: TEST RAPIDE\n",
            "  üìÇ Chemin donn√©es: /content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys/data\n",
            "  üë• Max utilisateurs: 1000\n",
            "  üéΩ Max articles: 500\n",
            "  üè∑Ô∏è Features utilis√©es: 3\n",
            "  ü§ñ Type de mod√®le: Hybride\n",
            "\n",
            "üìä R√âSULTATS FINAUX:\n",
            "  üë• Utilisateurs trait√©s: 998\n",
            "  üëï Articles trait√©s: 500\n",
            "  ü§ù Mod√®le collaboratif AUC: 0.5314\n",
            "  üîÄ Mod√®le final AUC: 0.7111\n",
            "  üìà Am√©lioration hybride: +33.80%\n",
            "\n",
            "üíæ FICHIERS SAUVEGARD√âS DANS: /content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys/outputs/run_20250928_113619\n",
            "  üìÅ sample_data.pkl\n",
            "  üìÅ prepared_data.pkl\n",
            "  üìÅ final_recommendation_system.pkl\n",
            "  üìÅ execution_log.txt\n",
            "\n",
            "üÜî ID EX√âCUTION: run_20250928_113619\n",
            "‚úÖ Syst√®me de recommandation op√©rationnel\n",
            "‚úÖ Tests de validation effectu√©s\n",
            "\n",
            "üí° Pour un run complet, changez QUICK_TEST_MODE = False dans la config\n",
            "\n",
            "üéØ RECOMMANDATIONS POUR LA PROCHAINE √âTAPE:\n",
            "  üöÄ Testez en mode complet pour de meilleures performances\n",
            "  üìä Analysez les r√©sultats dans le fichier de log\n",
            "\n",
            "üöÄ Pipeline pr√™t pour la production !\n",
            "\n",
            "üìù Log complet disponible: /content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys/outputs/run_20250928_113619/execution_log.txt\n",
            "\n",
            "============================================================\n",
            "üìã GUIDE RAPIDE POUR UTILISER CE PIPELINE\n",
            "============================================================\n",
            "\n",
            "üîß POUR PERSONNALISER LE PIPELINE:\n",
            "\n",
            "1. CHANGEZ CES VARIABLES AU D√âBUT DU CODE:\n",
            "   ‚Ä¢ USER_BASE_PATH = \"/votre/chemin/vers/donn√©es\"\n",
            "   ‚Ä¢ USER_DATA_FOLDER = \"nom_dossier_csv\"\n",
            "   ‚Ä¢ QUICK_TEST_MODE = True/False\n",
            "\n",
            "2. AJUSTEZ LES PARAM√àTRES SELON VOS BESOINS:\n",
            "   ‚Ä¢ USER_QUICK_MAX_USERS = nombre d'utilisateurs max\n",
            "   ‚Ä¢ USER_ARTICLE_FEATURES = ['colonne1', 'colonne2', ...]\n",
            "   ‚Ä¢ USER_LOSS_FUNCTIONS = ['warp', 'bpr', 'logistic']\n",
            "\n",
            "3. LANCEZ LE CODE ET V√âRIFIEZ LES R√âSULTATS DANS:\n",
            "   /content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys/outputs/run_20250928_113619\n",
            "\n",
            "üöÄ PR√äT √Ä UTILISER - AUCUNE AUTRE MODIFICATION N√âCESSAIRE!\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nüöÄ 10. PIPELINE FINAL ET TESTS\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Classe pour le syst√®me de recommandation\n",
        "class HMRecommendationSystem:\n",
        "    def __init__(self, model, dataset=None, item_features_matrix=None, user_encoder=None, item_encoder=None):\n",
        "        self.model = model\n",
        "        self.dataset = dataset\n",
        "        self.item_features_matrix = item_features_matrix\n",
        "        self.user_encoder = user_encoder\n",
        "        self.item_encoder = item_encoder\n",
        "        self.is_hybrid = dataset is not None and item_features_matrix is not None\n",
        "\n",
        "    def get_user_recommendations(self, customer_id, n_recommendations=10):\n",
        "        \"\"\"Obtient des recommandations pour un utilisateur\"\"\"\n",
        "        try:\n",
        "            if self.is_hybrid:\n",
        "                # Mode hybride - utilise le dataset LightFM\n",
        "                user_mapping = self.dataset.mapping()[0]\n",
        "                item_mapping = self.dataset.mapping()[2]\n",
        "\n",
        "                if customer_id not in user_mapping:\n",
        "                    print(f\"Utilisateur {customer_id} non trouv√© dans le dataset hybride\")\n",
        "                    return []\n",
        "\n",
        "                user_id = user_mapping[customer_id]\n",
        "                item_ids = list(range(len(item_mapping)))\n",
        "                user_ids = [user_id] * len(item_ids)\n",
        "\n",
        "                scores = self.model.predict(user_ids, item_ids, item_features=self.item_features_matrix)\n",
        "\n",
        "                top_items = np.argsort(scores)[::-1][:n_recommendations]\n",
        "                reverse_item_mapping = {v: k for k, v in item_mapping.items()}\n",
        "                top_articles = [reverse_item_mapping[i] for i in top_items]\n",
        "                top_scores = scores[top_items]\n",
        "\n",
        "            else:\n",
        "                # Mode collaboratif classique\n",
        "                user_id = self.user_encoder.transform([customer_id])[0]\n",
        "\n",
        "                # Cr√©er des arrays pour tous les articles\n",
        "                user_ids = np.array([user_id] * len(self.item_encoder.classes_))\n",
        "                item_ids = np.arange(len(self.item_encoder.classes_))\n",
        "\n",
        "                scores = self.model.predict(user_ids, item_ids)\n",
        "\n",
        "                top_items = np.argsort(scores)[::-1][:n_recommendations]\n",
        "                top_articles = self.item_encoder.inverse_transform(top_items)\n",
        "                top_scores = scores[top_items]\n",
        "\n",
        "            return list(zip(top_articles, top_scores))\n",
        "\n",
        "        except (ValueError, KeyError) as e:\n",
        "            print(f\"Erreur pour utilisateur {customer_id}: {e}\")\n",
        "            return []\n",
        "\n",
        "    def get_similar_items(self, article_id, n_similar=10):\n",
        "        \"\"\"Trouve des articles similaires bas√©s sur les embeddings\"\"\"\n",
        "        try:\n",
        "            if self.is_hybrid:\n",
        "                # Mode hybride\n",
        "                item_mapping = self.dataset.mapping()[2]\n",
        "                if article_id not in item_mapping:\n",
        "                    print(f\"Article {article_id} non trouv√© dans le dataset hybride\")\n",
        "                    return []\n",
        "\n",
        "                item_id = item_mapping[article_id]\n",
        "            else:\n",
        "                # Mode collaboratif\n",
        "                item_id = self.item_encoder.transform([article_id])[0]\n",
        "\n",
        "            # Obtenir les embeddings d'articles\n",
        "            item_embeddings = self.model.item_embeddings\n",
        "\n",
        "            # Calculer la similarit√© cosinus\n",
        "            target_embedding = item_embeddings[item_id]\n",
        "            similarities = np.dot(item_embeddings, target_embedding)\n",
        "\n",
        "            # Articles les plus similaires (exclure l'article lui-m√™me)\n",
        "            similar_items = np.argsort(similarities)[::-1][1:n_similar+1]\n",
        "\n",
        "            if self.is_hybrid:\n",
        "                reverse_item_mapping = {v: k for k, v in item_mapping.items()}\n",
        "                similar_articles = [reverse_item_mapping[i] for i in similar_items]\n",
        "            else:\n",
        "                similar_articles = self.item_encoder.inverse_transform(similar_items)\n",
        "\n",
        "            similarity_scores = similarities[similar_items]\n",
        "\n",
        "            return list(zip(similar_articles, similarity_scores))\n",
        "\n",
        "        except (ValueError, KeyError) as e:\n",
        "            print(f\"Erreur pour article {article_id}: {e}\")\n",
        "            return []\n",
        "\n",
        "# Initialisation du syst√®me\n",
        "print(\"üîß Initialisation du syst√®me de recommandation...\")\n",
        "\n",
        "if feature_columns:\n",
        "    # Syst√®me hybride\n",
        "    recommender = HMRecommendationSystem(\n",
        "        model=hybrid_model,\n",
        "        dataset=dataset,\n",
        "        item_features_matrix=item_features_matrix,\n",
        "        user_encoder=user_encoder,\n",
        "        item_encoder=item_encoder\n",
        "    )\n",
        "    print(\"‚úÖ Syst√®me de recommandation hybride initialis√©\")\n",
        "else:\n",
        "    # Syst√®me collaboratif\n",
        "    recommender = HMRecommendationSystem(\n",
        "        model=best_optimized_model,\n",
        "        user_encoder=user_encoder,\n",
        "        item_encoder=item_encoder\n",
        "    )\n",
        "    print(\"‚úÖ Syst√®me de recommandation collaboratif initialis√©\")\n",
        "\n",
        "# Tests du syst√®me\n",
        "print(\"\\nüß™ TESTS DU SYST√àME DE RECOMMANDATION\")\n",
        "\n",
        "# Test avec quelques utilisateurs\n",
        "test_users = transactions_sample['customer_id'].unique()[:3]\n",
        "\n",
        "for customer_id in test_users:\n",
        "    print(f\"\\nüë§ Recommandations pour le client {customer_id}:\")\n",
        "    recommendations = recommender.get_user_recommendations(customer_id, 3)\n",
        "\n",
        "    if recommendations:\n",
        "        for i, (article_id, score) in enumerate(recommendations[:3], 1):\n",
        "            article_info = articles_sample[articles_sample['article_id'] == article_id]\n",
        "            if not article_info.empty and 'product_type_name' in article_info.columns:\n",
        "                product_name = article_info.iloc[0].get('product_type_name', 'N/A')\n",
        "                color = article_info.iloc[0].get('colour_group_name', 'N/A')\n",
        "                print(f\"  {i}. Article {article_id} - {product_name} ({color}) - Score: {score:.3f}\")\n",
        "            else:\n",
        "                print(f\"  {i}. Article {article_id} - Score: {score:.3f}\")\n",
        "    else:\n",
        "        print(\"  Aucune recommandation disponible\")\n",
        "\n",
        "# Test similarit√© d'articles\n",
        "print(f\"\\nüîç TEST SIMILARIT√â D'ARTICLES\")\n",
        "test_article = transactions_sample['article_id'].iloc[0]\n",
        "similar_items = recommender.get_similar_items(test_article, 3)\n",
        "\n",
        "if similar_items:\n",
        "    print(f\"Articles similaires √† {test_article}:\")\n",
        "    for i, (article_id, similarity) in enumerate(similar_items[:3], 1):\n",
        "        print(f\"  {i}. Article {article_id} - Similarit√©: {similarity:.3f}\")\n",
        "else:\n",
        "    print(\"Aucun article similaire trouv√©\")\n",
        "\n",
        "# Sauvegarde finale (MODIFI√â pour inclure la configuration utilisateur)\n",
        "final_results = {\n",
        "    'user_configuration': {\n",
        "        'BASE_PATH': BASE_PATH,\n",
        "        'DATA_PATH': DATA_PATH,\n",
        "        'QUICK_TEST_MODE': QUICK_TEST_MODE,\n",
        "        'MAX_USERS': MAX_USERS,\n",
        "        'MAX_ARTICLES': MAX_ARTICLES,\n",
        "        'EPOCHS_COLLABORATIVE': EPOCHS_COLLABORATIVE,\n",
        "        'EPOCHS_HYBRID': EPOCHS_HYBRID,\n",
        "        'ARTICLE_FEATURES': ARTICLE_FEATURES,\n",
        "        'LOSS_FUNCTIONS': LOSS_FUNCTIONS,\n",
        "        'feature_columns_used': feature_columns\n",
        "    },\n",
        "    'recommender': recommender,\n",
        "    'collaborative_auc': best_optimized_score,\n",
        "    'hybrid_auc': hybrid_auc,\n",
        "    'improvement': improvement,\n",
        "    'best_params': best_params,\n",
        "    'evaluation_results': evaluation_results,\n",
        "    'model_type': 'hybrid' if feature_columns else 'collaborative'\n",
        "}\n",
        "\n",
        "final_path = f\"{OUTPUTS_PATH}/final_recommendation_system.pkl\"\n",
        "with open(final_path, 'wb') as f:\n",
        "    pickle.dump(final_results, f)\n",
        "\n",
        "log_step(\"Pipeline termin√© avec succ√®s\", f\"Fichiers sauvegard√©s dans: {OUTPUTS_PATH}\")\n",
        "\n",
        "# =============================================================================\n",
        "# R√âSUM√â FINAL\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ PIPELINE TERMIN√â AVEC SUCC√àS !\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nüìã CONFIGURATION UTILIS√âE:\")\n",
        "print(f\"  üîß Mode: {'TEST RAPIDE' if QUICK_TEST_MODE else 'COMPLET'}\")\n",
        "print(f\"  üìÇ Chemin donn√©es: {DATA_PATH}\")\n",
        "print(f\"  üë• Max utilisateurs: {MAX_USERS}\")\n",
        "print(f\"  üéΩ Max articles: {MAX_ARTICLES}\")\n",
        "print(f\"  üè∑Ô∏è Features utilis√©es: {len(feature_columns) if feature_columns else 0}\")\n",
        "print(f\"  ü§ñ Type de mod√®le: {'Hybride' if feature_columns else 'Collaboratif'}\")\n",
        "\n",
        "print(f\"\\nüìä R√âSULTATS FINAUX:\")\n",
        "print(f\"  üë• Utilisateurs trait√©s: {num_users:,}\")\n",
        "print(f\"  üëï Articles trait√©s: {num_items:,}\")\n",
        "print(f\"  ü§ù Mod√®le collaboratif AUC: {best_optimized_score:.4f}\")\n",
        "print(f\"  üîÄ Mod√®le final AUC: {hybrid_auc:.4f}\")\n",
        "if feature_columns:\n",
        "    print(f\"  üìà Am√©lioration hybride: {improvement:+.2f}%\")\n",
        "\n",
        "print(f\"\\nüíæ FICHIERS SAUVEGARD√âS DANS: {OUTPUTS_PATH}\")\n",
        "print(f\"  üìÅ sample_data.pkl\")\n",
        "print(f\"  üìÅ prepared_data.pkl\")\n",
        "print(f\"  üìÅ final_recommendation_system.pkl\")\n",
        "print(f\"  üìÅ execution_log.txt\")\n",
        "\n",
        "if CREATE_TIMESTAMPED_OUTPUT:\n",
        "    print(f\"\\nüÜî ID EX√âCUTION: {run_id}\")\n",
        "\n",
        "print(\"‚úÖ Syst√®me de recommandation op√©rationnel\")\n",
        "print(\"‚úÖ Tests de validation effectu√©s\")\n",
        "\n",
        "if QUICK_TEST_MODE:\n",
        "    print(\"\\nüí° Pour un run complet, changez QUICK_TEST_MODE = False dans la config\")\n",
        "\n",
        "print(f\"\\nüéØ RECOMMANDATIONS POUR LA PROCHAINE √âTAPE:\")\n",
        "if not feature_columns:\n",
        "    print(\"  üìã V√©rifiez la disponibilit√© des features d'articles dans vos donn√©es\")\n",
        "    print(\"  üîß Ajustez USER_ARTICLE_FEATURES selon vos colonnes disponibles\")\n",
        "if QUICK_TEST_MODE:\n",
        "    print(\"  üöÄ Testez en mode complet pour de meilleures performances\")\n",
        "print(\"  üìä Analysez les r√©sultats dans le fichier de log\")\n",
        "\n",
        "print(\"\\nüöÄ Pipeline pr√™t pour la production !\")\n",
        "\n",
        "# Finalisation du log (MODIFI√â pour inclure la configuration)\n",
        "with open(log_file, 'a') as f:\n",
        "    f.write(\"=\"*50 + \"\\n\")\n",
        "    f.write(f\"EX√âCUTION TERMIN√âE √Ä: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "    f.write(f\"CONFIGURATION FINALE:\\n\")\n",
        "    f.write(f\"  - Mode: {'TEST RAPIDE' if QUICK_TEST_MODE else 'COMPLET'}\\n\")\n",
        "    f.write(f\"  - Chemin donn√©es: {DATA_PATH}\\n\")\n",
        "    f.write(f\"  - Features utilis√©es: {feature_columns}\\n\")\n",
        "    f.write(f\"R√âSULTATS FINAUX:\\n\")\n",
        "    f.write(f\"  - Utilisateurs: {num_users:,}\\n\")\n",
        "    f.write(f\"  - Articles: {num_items:,}\\n\")\n",
        "    f.write(f\"  - AUC Collaboratif: {best_optimized_score:.4f}\\n\")\n",
        "    f.write(f\"  - AUC Final: {hybrid_auc:.4f}\\n\")\n",
        "    if feature_columns:\n",
        "        f.write(f\"  - Am√©lioration: {improvement:+.2f}%\\n\")\n",
        "    f.write(f\"  - Type mod√®le: {'Hybride' if feature_columns else 'Collaboratif'}\\n\")\n",
        "\n",
        "print(f\"\\nüìù Log complet disponible: {log_file}\")\n",
        "\n",
        "# =============================================================================\n",
        "# üìã GUIDE RAPIDE POUR L'UTILISATEUR\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìã GUIDE RAPIDE POUR UTILISER CE PIPELINE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\"\"\n",
        "üîß POUR PERSONNALISER LE PIPELINE:\n",
        "\n",
        "1. CHANGEZ CES VARIABLES AU D√âBUT DU CODE:\n",
        "   ‚Ä¢ USER_BASE_PATH = \"/votre/chemin/vers/donn√©es\"\n",
        "   ‚Ä¢ USER_DATA_FOLDER = \"nom_dossier_csv\"\n",
        "   ‚Ä¢ QUICK_TEST_MODE = True/False\n",
        "\n",
        "2. AJUSTEZ LES PARAM√àTRES SELON VOS BESOINS:\n",
        "   ‚Ä¢ USER_QUICK_MAX_USERS = nombre d'utilisateurs max\n",
        "   ‚Ä¢ USER_ARTICLE_FEATURES = ['colonne1', 'colonne2', ...]\n",
        "   ‚Ä¢ USER_LOSS_FUNCTIONS = ['warp', 'bpr', 'logistic']\n",
        "\n",
        "3. LANCEZ LE CODE ET V√âRIFIEZ LES R√âSULTATS DANS:\n",
        "   {OUTPUTS_PATH}\n",
        "\n",
        "üöÄ PR√äT √Ä UTILISER - AUCUNE AUTRE MODIFICATION N√âCESSAIRE!\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*60)"
      ]
    }
  ]
}