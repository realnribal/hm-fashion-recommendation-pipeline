{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "G6jnAxdkCBuv",
        "U4CJ2BI5CxEF",
        "n8A2rmyQDBfr",
        "A93ZcKEQDUcA",
        "ysa8DIzBDlNe",
        "kItbPEXaDwQ9",
        "zW_6uYlhD8Hz"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# H&M Fashion Recommendation Pipeline\n",
        "\n",
        "Ce notebook implÃ©mente un pipeline de recommandation pour les donnÃ©es de mode H&M en utilisant LightFM. Il comprend le chargement des donnÃ©es, le prÃ©traitement, le filtrage collaboratif, l'optimisation des hyperparamÃ¨tres et un modÃ¨le hybride intÃ©grant des caractÃ©ristiques d'articles. Le pipeline Ã©value les performances du modÃ¨le et fournit un objet systÃ¨me de recommandation final pour faire des prÃ©dictions."
      ],
      "metadata": {
        "id": "I5t57G7ABJhz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. CELLULE DE CONFIGURATION - MODIFIEZ UNIQUEMENT CETTE SECTION"
      ],
      "metadata": {
        "id": "G6jnAxdkCBuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "QUICK_TEST_MODE = True  # True pour test rapide, False pour run complet\n",
        "\n",
        "# Chemin de base vers vos donnÃ©es (MODIFIEZ CETTE LIGNE)\n",
        "USER_BASE_PATH = \"/content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys\"\n",
        "\n",
        "# Nom du dossier contenant les fichiers CSV (modifiez si diffÃ©rent)\n",
        "USER_DATA_FOLDER = \"data\"\n",
        "\n",
        "# CrÃ©er un dossier unique pour chaque exÃ©cution ?\n",
        "CREATE_TIMESTAMPED_OUTPUT = True\n",
        "\n",
        "# ========================================\n",
        "# PARAMÃˆTRES AVANCÃ‰S (OPTIONNEL)\n",
        "# ========================================\n",
        "\n",
        "# Ã‰chantillonnage (mode rapide)\n",
        "USER_QUICK_MAX_USERS = 1000\n",
        "USER_QUICK_MAX_ARTICLES = 500\n",
        "USER_QUICK_MIN_TRANSACTIONS = 10\n",
        "USER_QUICK_MIN_PURCHASES = 50\n",
        "USER_QUICK_EPOCHS_COLLABORATIVE = 2\n",
        "USER_QUICK_EPOCHS_HYBRID = 5\n",
        "\n",
        "# Ã‰chantillonnage (mode complet) - None = toutes les donnÃ©es\n",
        "USER_FULL_MAX_USERS = None\n",
        "USER_FULL_MAX_ARTICLES = None\n",
        "USER_FULL_MIN_TRANSACTIONS = 5\n",
        "USER_FULL_MIN_PURCHASES = 10\n",
        "USER_FULL_EPOCHS_COLLABORATIVE = 5\n",
        "USER_FULL_EPOCHS_HYBRID = 50\n",
        "\n",
        "# Features articles Ã  utiliser (ajoutez/supprimez selon vos donnÃ©es)\n",
        "USER_ARTICLE_FEATURES = ['product_type_name', 'product_group_name', 'colour_group_name']\n",
        "\n",
        "# Loss functions Ã  tester\n",
        "USER_LOSS_FUNCTIONS = ['warp', 'bpr']  # Ajoutez 'logistic'\n",
        "\n",
        "# Grille hyperparamÃ¨tres (mode rapide)\n",
        "USER_QUICK_PARAM_GRID = {\n",
        "    'no_components': [64, 128],\n",
        "    'learning_rate': [0.05, 0.1],\n",
        "    'item_alpha': [1e-5, 1e-4],\n",
        "    'user_alpha': [1e-5, 1e-4]\n",
        "}\n",
        "\n",
        "# Grille hyperparamÃ¨tres (mode complet)\n",
        "USER_FULL_PARAM_GRID = {\n",
        "    'no_components': [64, 128, 256],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'item_alpha': [0.0, 1e-6, 1e-5, 1e-4],\n",
        "    'user_alpha': [0.0, 1e-6, 1e-5, 1e-4]\n",
        "}\n",
        "\n",
        "# ========================================\n",
        "# ğŸ”§ CONFIGURATION AUTOMATIQUE (NE PAS MODIFIER)\n",
        "# ========================================\n",
        "\n",
        "# Application automatique des paramÃ¨tres selon le mode\n",
        "if QUICK_TEST_MODE:\n",
        "    print(\"ğŸš€ MODE TEST RAPIDE ACTIVÃ‰\")\n",
        "    print(\"ğŸ“ Ã‰chantillons rÃ©duits et moins d'epochs pour validation rapide\")\n",
        "    MAX_USERS = USER_QUICK_MAX_USERS\n",
        "    MAX_ARTICLES = USER_QUICK_MAX_ARTICLES\n",
        "    EPOCHS_COLLABORATIVE = USER_QUICK_EPOCHS_COLLABORATIVE\n",
        "    EPOCHS_HYBRID = USER_QUICK_EPOCHS_HYBRID\n",
        "    MIN_TRANSACTIONS = USER_QUICK_MIN_TRANSACTIONS\n",
        "    MIN_PURCHASES = USER_QUICK_MIN_PURCHASES\n",
        "    PARAM_GRID = USER_QUICK_PARAM_GRID\n",
        "else:\n",
        "    print(\"ğŸŒ MODE COMPLET ACTIVÃ‰\")\n",
        "    MAX_USERS = USER_FULL_MAX_USERS\n",
        "    MAX_ARTICLES = USER_FULL_MAX_ARTICLES\n",
        "    EPOCHS_COLLABORATIVE = USER_FULL_EPOCHS_COLLABORATIVE\n",
        "    EPOCHS_HYBRID = USER_FULL_EPOCHS_HYBRID\n",
        "    MIN_TRANSACTIONS = USER_FULL_MIN_TRANSACTIONS\n",
        "    MIN_PURCHASES = USER_FULL_MIN_PURCHASES\n",
        "    PARAM_GRID = USER_FULL_PARAM_GRID\n",
        "\n",
        "# Configuration des chemins\n",
        "BASE_PATH = USER_BASE_PATH\n",
        "DATA_PATH = f\"{BASE_PATH}/{USER_DATA_FOLDER}\"\n",
        "ARTICLE_FEATURES = USER_ARTICLE_FEATURES\n",
        "LOSS_FUNCTIONS = USER_LOSS_FUNCTIONS\n",
        "\n",
        "print(\"ğŸ›ï¸ PIPELINE COMPLET DE RECOMMANDATION H&M FASHION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"ğŸ“‚ Chemin donnÃ©es: {DATA_PATH}\")\n",
        "print(f\"ğŸ‘¥ Max utilisateurs: {MAX_USERS}\")\n",
        "print(f\"ğŸ½ Max articles: {MAX_ARTICLES}\")\n",
        "print(f\"ğŸ·ï¸ Features: {len(ARTICLE_FEATURES)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82gCNPaaCmFs",
        "outputId": "5dea7f02-510d-48f5-bf9f-8ae7a4fc76d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ MODE TEST RAPIDE ACTIVÃ‰\n",
            "ğŸ“ Ã‰chantillons rÃ©duits et moins d'epochs pour validation rapide\n",
            "ğŸ›ï¸ PIPELINE COMPLET DE RECOMMANDATION H&M FASHION\n",
            "============================================================\n",
            "ğŸ“‚ Chemin donnÃ©es: /content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys/data\n",
            "ğŸ‘¥ Max utilisateurs: 1000\n",
            "ğŸ½ Max articles: 500\n",
            "ğŸ·ï¸ Features: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. CONFIGURATION ET SETUP"
      ],
      "metadata": {
        "id": "U4CJ2BI5CxEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nğŸ“— 1. CONFIGURATION ET SETUP\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "print(\"ğŸ”— Connexion Ã  Google Drive...\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"âœ… Google Drive montÃ© avec succÃ¨s\")\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"\\nğŸ—‚ Configuration des chemins de travail...\")\n",
        "\n",
        "# CrÃ©ation d'un rÃ©pertoire unique pour chaque exÃ©cution (MODIFIÃ‰)\n",
        "if CREATE_TIMESTAMPED_OUTPUT:\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    run_id = f\"run_{timestamp}\"\n",
        "    OUTPUTS_PATH = f\"{BASE_PATH}/outputs/{run_id}\"\n",
        "else:\n",
        "    OUTPUTS_PATH = f\"{BASE_PATH}/outputs\"\n",
        "\n",
        "# CrÃ©ation du rÃ©pertoire de sortie\n",
        "os.makedirs(OUTPUTS_PATH, exist_ok=True)\n",
        "\n",
        "print(f\"ğŸ“‚ Chemin de base : {BASE_PATH}\")\n",
        "print(f\"ğŸ“‚ DonnÃ©es : {DATA_PATH}\")\n",
        "print(f\"ğŸ“‚ Sorties : {OUTPUTS_PATH}\")\n",
        "if CREATE_TIMESTAMPED_OUTPUT:\n",
        "    print(f\"ğŸ†” ID d'exÃ©cution : {run_id}\")\n",
        "\n",
        "# CrÃ©ation d'un fichier de log pour cette exÃ©cution\n",
        "log_file = f\"{OUTPUTS_PATH}/execution_log.txt\"\n",
        "with open(log_file, 'w') as f:\n",
        "    f.write(f\"ExÃ©cution du pipeline H&M Fashion Recommendation\\n\")\n",
        "    f.write(f\"Date/Heure: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "    f.write(f\"Mode: {'TEST RAPIDE' if QUICK_TEST_MODE else 'COMPLET'}\\n\")\n",
        "    f.write(f\"RÃ©pertoire: {OUTPUTS_PATH}\\n\")\n",
        "    f.write(f\"ParamÃ¨tres utilisateur appliquÃ©s:\\n\")\n",
        "    f.write(f\"  - BASE_PATH: {BASE_PATH}\\n\")\n",
        "    f.write(f\"  - MAX_USERS: {MAX_USERS}\\n\")\n",
        "    f.write(f\"  - MAX_ARTICLES: {MAX_ARTICLES}\\n\")\n",
        "    f.write(f\"  - EPOCHS_COLLABORATIVE: {EPOCHS_COLLABORATIVE}\\n\")\n",
        "    f.write(f\"  - EPOCHS_HYBRID: {EPOCHS_HYBRID}\\n\")\n",
        "    f.write(\"=\"*50 + \"\\n\\n\")\n",
        "\n",
        "print(f\"ğŸ“ Log d'exÃ©cution crÃ©Ã© : {log_file}\")\n",
        "\n",
        "print(\"\\nğŸ“¦ Installation des bibliothÃ¨ques...\")\n",
        "!pip install git+https://github.com/daviddavo/lightfm -q\n",
        "!pip install -q tqdm\n",
        "\n",
        "# Imports\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from scipy.sparse import coo_matrix, csr_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
        "from lightfm import LightFM\n",
        "from lightfm.data import Dataset\n",
        "from lightfm.evaluation import precision_at_k, recall_at_k, auc_score\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"âœ… Configuration terminÃ©e\")\n",
        "\n",
        "# Fonction utilitaire pour logguer les Ã©tapes importantes\n",
        "def log_step(step_name, details=\"\"):\n",
        "    \"\"\"Log une Ã©tape dans le fichier de log\"\"\"\n",
        "    timestamp = datetime.now().strftime('%H:%M:%S')\n",
        "    with open(log_file, 'a') as f:\n",
        "        f.write(f\"[{timestamp}] {step_name}\\n\")\n",
        "        if details:\n",
        "            f.write(f\"  {details}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "    print(f\"ğŸ“ Ã‰tape loggÃ©e: {step_name}\")\n",
        "\n",
        "log_step(\"Configuration terminÃ©e\", f\"RÃ©pertoire de sortie: {OUTPUTS_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1eAsHfDC2Qu",
        "outputId": "dd025eb9-48a5-4098-9369-2001fe67197f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“— 1. CONFIGURATION ET SETUP\n",
            "------------------------------\n",
            "ğŸ”— Connexion Ã  Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Google Drive montÃ© avec succÃ¨s\n",
            "\n",
            "ğŸ—‚ Configuration des chemins de travail...\n",
            "ğŸ“‚ Chemin de base : /content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys\n",
            "ğŸ“‚ DonnÃ©es : /content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys/data\n",
            "ğŸ“‚ Sorties : /content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys/outputs/run_20250928_113619\n",
            "ğŸ†” ID d'exÃ©cution : run_20250928_113619\n",
            "ğŸ“ Log d'exÃ©cution crÃ©Ã© : /content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys/outputs/run_20250928_113619/execution_log.txt\n",
            "\n",
            "ğŸ“¦ Installation des bibliothÃ¨ques...\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "âœ… Configuration terminÃ©e\n",
            "ğŸ“ Ã‰tape loggÃ©e: Configuration terminÃ©e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. CHARGEMENT DES DONNÃ‰ES"
      ],
      "metadata": {
        "id": "n8A2rmyQDBfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nğŸ“Š 2. CHARGEMENT DES DONNÃ‰ES\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "files_to_check = [\n",
        "    f\"{DATA_PATH}/transactions_train.csv\",\n",
        "    f\"{DATA_PATH}/customers.csv\",\n",
        "    f\"{DATA_PATH}/articles.csv\"\n",
        "]\n",
        "\n",
        "for file_path in files_to_check:\n",
        "    if os.path.exists(file_path):\n",
        "        size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
        "        print(f\"âœ… {os.path.basename(file_path)}: {size_mb:.1f} MB\")\n",
        "    else:\n",
        "        print(f\"âŒ Fichier manquant: {os.path.basename(file_path)}\")\n",
        "\n",
        "print(\"\\nâ³ Chargement en cours...\")\n",
        "\n",
        "try:\n",
        "    transactions = pd.read_csv(f\"{DATA_PATH}/transactions_train.csv\")\n",
        "    customers = pd.read_csv(f\"{DATA_PATH}/customers.csv\")\n",
        "    articles = pd.read_csv(f\"{DATA_PATH}/articles.csv\")\n",
        "\n",
        "    print(f\"ğŸ“ˆ Transactions: {len(transactions):,} lignes\")\n",
        "    print(f\"ğŸ‘¥ Clients: {len(customers):,} lignes\")\n",
        "    print(f\"ğŸ‘• Articles: {len(articles):,} lignes\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"âŒ Erreur de chargement: {e}\")\n",
        "    print(f\"ğŸ” VÃ©rifiez que le chemin est correct: {DATA_PATH}\")\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIHsfsTkDFv2",
        "outputId": "1f29ad5a-4741-4956-cf4d-a49a291e6bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š 2. CHARGEMENT DES DONNÃ‰ES\n",
            "------------------------------\n",
            "âœ… transactions_train.csv: 3326.4 MB\n",
            "âœ… customers.csv: 197.5 MB\n",
            "âœ… articles.csv: 34.5 MB\n",
            "\n",
            "â³ Chargement en cours...\n",
            "ğŸ“ˆ Transactions: 31,788,324 lignes\n",
            "ğŸ‘¥ Clients: 1,371,980 lignes\n",
            "ğŸ‘• Articles: 105,542 lignes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. EXPLORATION RAPIDE DES DONNÃ‰ES"
      ],
      "metadata": {
        "id": "Gz4piYkaDKXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 3. EXPLORATION RAPIDE DES DONNÃ‰ES\n",
        "# =============================================================================\n",
        "print(\"\\nğŸ” 3. EXPLORATION RAPIDE DES DONNÃ‰ES\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Informations gÃ©nÃ©rales\n",
        "print(f\"ğŸ“Š PÃ©riode des transactions: {transactions['t_dat'].min()} Ã  {transactions['t_dat'].max()}\")\n",
        "print(f\"ğŸ‘¥ Clients uniques: {transactions['customer_id'].nunique():,}\")\n",
        "print(f\"ğŸ‘• Articles uniques: {transactions['article_id'].nunique():,}\")\n",
        "print(f\"ğŸ’° Prix mÃ©dian: {transactions['price'].median():.2f}\")\n",
        "\n",
        "# Conversion de dates\n",
        "transactions['t_dat'] = pd.to_datetime(transactions['t_dat'])\n",
        "\n",
        "# =============================================================================\n",
        "# 4. Ã‰CHANTILLONNAGE STRATÃ‰GIQUE OPTIMISÃ‰\n",
        "# =============================================================================\n",
        "print(\"\\nğŸ¯ 4. Ã‰CHANTILLONNAGE STRATÃ‰GIQUE\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Analyse de l'activitÃ© des utilisateurs\n",
        "user_activity = transactions.groupby('customer_id').size().sort_values(ascending=False)\n",
        "print(f\"ğŸ‘¥ Clients uniques: {len(user_activity):,}\")\n",
        "print(f\"ğŸ“Š Transactions par client - MÃ©diane: {user_activity.median():.0f}\")\n",
        "\n",
        "# Clients actifs (configuration optimisÃ©e)\n",
        "active_users = user_activity[user_activity >= MIN_TRANSACTIONS].index\n",
        "if QUICK_TEST_MODE and len(active_users) > MAX_USERS:\n",
        "    active_users = active_users[:MAX_USERS]\n",
        "\n",
        "# Articles populaires\n",
        "article_popularity = transactions.groupby('article_id').size().sort_values(ascending=False)\n",
        "popular_articles = article_popularity[article_popularity >= MIN_PURCHASES].index\n",
        "if QUICK_TEST_MODE and len(popular_articles) > MAX_ARTICLES:\n",
        "    popular_articles = popular_articles[:MAX_ARTICLES]\n",
        "\n",
        "print(f\"ğŸ”¥ Clients actifs sÃ©lectionnÃ©s: {len(active_users):,}\")\n",
        "print(f\"ğŸ“ˆ Articles populaires sÃ©lectionnÃ©s: {len(popular_articles):,}\")\n",
        "\n",
        "# CrÃ©ation de l'Ã©chantillon\n",
        "sample_transactions = transactions[\n",
        "    (transactions['customer_id'].isin(active_users)) &\n",
        "    (transactions['article_id'].isin(popular_articles))\n",
        "].copy()\n",
        "\n",
        "print(f\"ğŸ“Š Ã‰chantillon crÃ©Ã©: {len(sample_transactions):,} transactions\")\n",
        "print(f\"ğŸ‘¥ Clients dans l'Ã©chantillon: {sample_transactions['customer_id'].nunique():,}\")\n",
        "print(f\"ğŸ‘• Articles dans l'Ã©chantillon: {sample_transactions['article_id'].nunique():,}\")\n",
        "\n",
        "# Sauvegarde\n",
        "os.makedirs(OUTPUTS_PATH, exist_ok=True)\n",
        "sample_data = {\n",
        "    'transactions': sample_transactions,\n",
        "    'customers': customers[customers['customer_id'].isin(sample_transactions['customer_id'])],\n",
        "    'articles': articles[articles['article_id'].isin(sample_transactions['article_id'])]\n",
        "}\n",
        "\n",
        "sample_path = f\"{OUTPUTS_PATH}/sample_data.pkl\"\n",
        "with open(sample_path, 'wb') as f:\n",
        "    pickle.dump(sample_data, f)\n",
        "\n",
        "print(f\"ğŸ’¾ Ã‰chantillon sauvegardÃ©: {sample_path}\")\n",
        "log_step(\"Ã‰chantillonnage terminÃ©\", f\"Transactions: {len(sample_transactions):,}, Users: {len(active_users):,}, Articles: {len(popular_articles):,}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgz1TDGpDR_I",
        "outputId": "b8b92832-6616-445f-cf03-1ead2d7aa92a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ” 3. EXPLORATION RAPIDE DES DONNÃ‰ES\n",
            "------------------------------\n",
            "ğŸ“Š PÃ©riode des transactions: 2018-09-20 Ã  2020-09-22\n",
            "ğŸ‘¥ Clients uniques: 1,362,281\n",
            "ğŸ‘• Articles uniques: 104,547\n",
            "ğŸ’° Prix mÃ©dian: 0.03\n",
            "\n",
            "ğŸ¯ 4. Ã‰CHANTILLONNAGE STRATÃ‰GIQUE\n",
            "------------------------------\n",
            "ğŸ‘¥ Clients uniques: 1,362,281\n",
            "ğŸ“Š Transactions par client - MÃ©diane: 9\n",
            "ğŸ”¥ Clients actifs sÃ©lectionnÃ©s: 1,000\n",
            "ğŸ“ˆ Articles populaires sÃ©lectionnÃ©s: 500\n",
            "ğŸ“Š Ã‰chantillon crÃ©Ã©: 41,850 transactions\n",
            "ğŸ‘¥ Clients dans l'Ã©chantillon: 998\n",
            "ğŸ‘• Articles dans l'Ã©chantillon: 500\n",
            "ğŸ’¾ Ã‰chantillon sauvegardÃ©: /content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys/outputs/run_20250928_113619/sample_data.pkl\n",
            "ğŸ“ Ã‰tape loggÃ©e: Ã‰chantillonnage terminÃ©\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. PRÃ‰PARATION DES DONNÃ‰ES\n"
      ],
      "metadata": {
        "id": "A93ZcKEQDUcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nğŸ”§ 5. PRÃ‰PARATION DES DONNÃ‰ES\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# RÃ©cupÃ©ration des donnÃ©es Ã©chantillonnÃ©es\n",
        "transactions_sample = sample_data['transactions']\n",
        "customers_sample = sample_data['customers']\n",
        "articles_sample = sample_data['articles']\n",
        "\n",
        "# Encodage des IDs\n",
        "user_encoder = LabelEncoder()\n",
        "item_encoder = LabelEncoder()\n",
        "\n",
        "transactions_sample['user_id'] = user_encoder.fit_transform(transactions_sample['customer_id'])\n",
        "transactions_sample['item_id'] = item_encoder.fit_transform(transactions_sample['article_id'])\n",
        "\n",
        "num_users = len(user_encoder.classes_)\n",
        "num_items = len(item_encoder.classes_)\n",
        "\n",
        "print(f\"ğŸ‘¥ Utilisateurs encodÃ©s: {num_users:,}\")\n",
        "print(f\"ğŸ‘• Articles encodÃ©s: {num_items:,}\")\n",
        "\n",
        "# Split temporel train/test avec sÃ©paration stricte des interactions\n",
        "split_date = transactions_sample['t_dat'].quantile(0.8)\n",
        "train_transactions = transactions_sample[transactions_sample['t_dat'] <= split_date]\n",
        "test_transactions = transactions_sample[transactions_sample['t_dat'] > split_date]\n",
        "\n",
        "print(f\"ğŸ“… Date de split: {split_date}\")\n",
        "print(f\"ğŸš‚ Train: {len(train_transactions):,} transactions\")\n",
        "print(f\"ğŸ§ª Test: {len(test_transactions):,} transactions\")\n",
        "\n",
        "# CrÃ©ation des matrices train/test\n",
        "train_matrix = csr_matrix(\n",
        "    (np.ones(len(train_transactions)),\n",
        "     (train_transactions['user_id'], train_transactions['item_id'])),\n",
        "    shape=(num_users, num_items)\n",
        ")\n",
        "\n",
        "# Pour le test, on ne garde que les nouvelles interactions (pas dans train)\n",
        "# CrÃ©er un set des interactions d'entraÃ®nement\n",
        "train_interactions_set = set(zip(train_transactions['user_id'], train_transactions['item_id']))\n",
        "\n",
        "# Filtrer les interactions de test pour exclure celles dÃ©jÃ  dans train\n",
        "test_filtered = []\n",
        "for _, row in test_transactions.iterrows():\n",
        "    user_item_pair = (row['user_id'], row['item_id'])\n",
        "    if user_item_pair not in train_interactions_set:\n",
        "        test_filtered.append(row)\n",
        "\n",
        "if test_filtered:\n",
        "    test_df = pd.DataFrame(test_filtered)\n",
        "    test_matrix = csr_matrix(\n",
        "        (np.ones(len(test_df)),\n",
        "         (test_df['user_id'], test_df['item_id'])),\n",
        "        shape=(num_users, num_items)\n",
        "    )\n",
        "    print(f\"ğŸ” Interactions test filtrÃ©es: {len(test_df):,} (nouvelles interactions uniquement)\")\n",
        "else:\n",
        "    # Si pas d'interactions nouvelles, crÃ©er un split utilisateur diffÃ©rent\n",
        "    print(\"âš ï¸  Pas de nouvelles interactions dans le test temporel, utilisation d'un split utilisateur...\")\n",
        "\n",
        "    # Split par utilisateur (80/20)\n",
        "    unique_users = transactions_sample['user_id'].unique()\n",
        "    np.random.seed(42)\n",
        "    np.random.shuffle(unique_users)\n",
        "\n",
        "    n_train_users = int(0.8 * len(unique_users))\n",
        "    train_users = unique_users[:n_train_users]\n",
        "    test_users = unique_users[n_train_users:]\n",
        "\n",
        "    train_transactions = transactions_sample[transactions_sample['user_id'].isin(train_users)]\n",
        "    test_transactions = transactions_sample[transactions_sample['user_id'].isin(test_users)]\n",
        "\n",
        "    train_matrix = csr_matrix(\n",
        "        (np.ones(len(train_transactions)),\n",
        "         (train_transactions['user_id'], train_transactions['item_id'])),\n",
        "        shape=(num_users, num_items)\n",
        "    )\n",
        "\n",
        "    test_matrix = csr_matrix(\n",
        "        (np.ones(len(test_transactions)),\n",
        "         (test_transactions['user_id'], test_transactions['item_id'])),\n",
        "        shape=(num_users, num_items)\n",
        "    )\n",
        "\n",
        "    print(f\"ğŸš‚ Train (utilisateurs): {len(train_transactions):,} transactions, {len(train_users):,} utilisateurs\")\n",
        "    print(f\"ğŸ§ª Test (utilisateurs): {len(test_transactions):,} transactions, {len(test_users):,} utilisateurs\")\n",
        "\n",
        "print(f\"ğŸ“Š Matrice train: {train_matrix.shape} - Interactions: {train_matrix.nnz:,}\")\n",
        "print(f\"ğŸ“Š Matrice test: {test_matrix.shape} - Interactions: {test_matrix.nnz:,}\")\n",
        "print(f\"ğŸ“Š DensitÃ© train: {train_matrix.nnz / (train_matrix.shape[0] * train_matrix.shape[1]):.6f}\")\n",
        "print(f\"ğŸ“Š DensitÃ© test: {test_matrix.nnz / (test_matrix.shape[0] * test_matrix.shape[1]):.6f}\")\n",
        "\n",
        "# VÃ©rification qu'il n'y a pas d'interactions communes\n",
        "common_interactions = train_matrix.multiply(test_matrix).nnz\n",
        "print(f\"ğŸ” Interactions communes (doit Ãªtre 0): {common_interactions}\")\n",
        "\n",
        "if common_interactions > 0:\n",
        "    print(\"âš ï¸  ATTENTION: Il y a encore des interactions communes!\")\n",
        "    print(\"ğŸ”§ Application d'un nettoyage supplÃ©mentaire...\")\n",
        "\n",
        "    # MÃ©thode alternative: masquer les interactions communes dans test\n",
        "    test_matrix_clean = test_matrix.copy()\n",
        "    test_matrix_clean[train_matrix.nonzero()] = 0\n",
        "    test_matrix_clean.eliminate_zeros()\n",
        "    test_matrix = test_matrix_clean\n",
        "\n",
        "    print(f\"âœ… Test nettoyÃ©: {test_matrix.nnz:,} interactions\")\n",
        "    print(f\"ğŸ” Interactions communes aprÃ¨s nettoyage: {train_matrix.multiply(test_matrix).nnz}\")\n",
        "\n",
        "assert train_matrix.multiply(test_matrix).nnz == 0, \"Erreur: interactions communes dÃ©tectÃ©es!\"\n",
        "print(\"âœ… Validation: Aucune interaction commune entre train et test\")\n",
        "\n",
        "# Sauvegarde\n",
        "prepared_data = {\n",
        "    'train_matrix': train_matrix,\n",
        "    'test_matrix': test_matrix,\n",
        "    'user_encoder': user_encoder,\n",
        "    'item_encoder': item_encoder,\n",
        "    'transactions_sample': transactions_sample,\n",
        "    'train_transactions': train_transactions,\n",
        "    'test_transactions': test_transactions\n",
        "}\n",
        "\n",
        "prepared_path = f\"{OUTPUTS_PATH}/prepared_data.pkl\"\n",
        "with open(prepared_path, 'wb') as f:\n",
        "    pickle.dump(prepared_data, f)\n",
        "\n",
        "print(f\"ğŸ’¾ DonnÃ©es prÃ©parÃ©es sauvegardÃ©es\")\n",
        "log_step(\"PrÃ©paration donnÃ©es terminÃ©e\", f\"Train: {train_matrix.nnz:,} interactions, Test: {test_matrix.nnz:,} interactions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWhwJ-MtDeFx",
        "outputId": "892c6fea-58a6-482e-c710-ea2b02710f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”§ 5. PRÃ‰PARATION DES DONNÃ‰ES\n",
            "------------------------------\n",
            "ğŸ‘¥ Utilisateurs encodÃ©s: 998\n",
            "ğŸ‘• Articles encodÃ©s: 500\n",
            "ğŸ“… Date de split: 2020-04-04 00:00:00\n",
            "ğŸš‚ Train: 33,627 transactions\n",
            "ğŸ§ª Test: 8,223 transactions\n",
            "ğŸ” Interactions test filtrÃ©es: 6,781 (nouvelles interactions uniquement)\n",
            "ğŸ“Š Matrice train: (998, 500) - Interactions: 19,996\n",
            "ğŸ“Š Matrice test: (998, 500) - Interactions: 4,588\n",
            "ğŸ“Š DensitÃ© train: 0.040072\n",
            "ğŸ“Š DensitÃ© test: 0.009194\n",
            "ğŸ” Interactions communes (doit Ãªtre 0): 0\n",
            "âœ… Validation: Aucune interaction commune entre train et test\n",
            "ğŸ’¾ DonnÃ©es prÃ©parÃ©es sauvegardÃ©es\n",
            "ğŸ“ Ã‰tape loggÃ©e: PrÃ©paration donnÃ©es terminÃ©e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. MODÃˆLE COLLABORATIF\n"
      ],
      "metadata": {
        "id": "ysa8DIzBDlNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nğŸ¤ 6. MODÃˆLE COLLABORATIF\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Test de diffÃ©rentes loss functions (MODIFIÃ‰ pour utiliser LOSS_FUNCTIONS)\n",
        "loss_functions = LOSS_FUNCTIONS\n",
        "models = {}\n",
        "results = {}\n",
        "\n",
        "for loss in loss_functions:\n",
        "    print(f\"\\nğŸ”„ EntraÃ®nement avec {loss.upper()}...\")\n",
        "\n",
        "    model = LightFM(loss=loss, random_state=42)\n",
        "    model.fit(train_matrix, epochs=EPOCHS_COLLABORATIVE, num_threads=2, verbose=True)\n",
        "\n",
        "    # Ã‰valuation\n",
        "    train_auc = auc_score(model, train_matrix).mean()\n",
        "    test_auc = auc_score(model, test_matrix, train_interactions=train_matrix).mean()\n",
        "    test_precision = precision_at_k(model, test_matrix, train_interactions=train_matrix, k=10).mean()\n",
        "\n",
        "    results[loss] = {\n",
        "        'train_auc': train_auc,\n",
        "        'test_auc': test_auc,\n",
        "        'test_precision': test_precision\n",
        "    }\n",
        "    models[loss] = model\n",
        "\n",
        "    print(f\"âœ… {loss.upper()} - AUC Test: {test_auc:.4f}, Precision@10: {test_precision:.4f}\")\n",
        "\n",
        "# SÃ©lection du meilleur modÃ¨le\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(f\"\\nğŸ“Š COMPARAISON DES MODÃˆLES:\")\n",
        "print(results_df)\n",
        "\n",
        "best_loss = results_df['test_auc'].idxmax()\n",
        "best_model = models[best_loss]\n",
        "best_score = results_df.loc[best_loss, 'test_auc']\n",
        "\n",
        "print(f\"\\nğŸ† Meilleur modÃ¨le: {best_loss.upper()} (AUC: {best_score:.4f})\")\n",
        "log_step(\"ModÃ¨le collaboratif terminÃ©\", f\"Meilleur: {best_loss.upper()}, AUC: {best_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn0HWlnfDo9r",
        "outputId": "c6f9ddbe-86d7-457e-ddbf-c0d06872efd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ¤ 6. MODÃˆLE COLLABORATIF\n",
            "------------------------------\n",
            "\n",
            "ğŸ”„ EntraÃ®nement avec WARP...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… WARP - AUC Test: 0.4585, Precision@10: 0.0139\n",
            "\n",
            "ğŸ”„ EntraÃ®nement avec BPR...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… BPR - AUC Test: 0.4973, Precision@10: 0.0096\n",
            "\n",
            "ğŸ“Š COMPARAISON DES MODÃˆLES:\n",
            "      train_auc  test_auc  test_precision\n",
            "warp   0.656556  0.458495        0.013901\n",
            "bpr    0.541479  0.497327        0.009641\n",
            "\n",
            "ğŸ† Meilleur modÃ¨le: BPR (AUC: 0.4973)\n",
            "ğŸ“ Ã‰tape loggÃ©e: ModÃ¨le collaboratif terminÃ©\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. OPTIMISATION DES HYPERPARAMÃˆTRES (RAPIDE)\n"
      ],
      "metadata": {
        "id": "kItbPEXaDwQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nğŸ”§ 7. OPTIMISATION DES HYPERPARAMÃˆTRES\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Grille rÃ©duite pour test rapide (MODIFIÃ‰ pour utiliser PARAM_GRID)\n",
        "param_grid = PARAM_GRID\n",
        "\n",
        "print(f\"ğŸ” Test de {np.prod([len(v) for v in param_grid.values()])} combinaisons...\")\n",
        "\n",
        "best_optimized_score = 0\n",
        "best_params = {}\n",
        "optimization_count = 0\n",
        "\n",
        "for no_components in param_grid['no_components']:\n",
        "    for learning_rate in param_grid['learning_rate']:\n",
        "        for item_alpha in param_grid['item_alpha']:\n",
        "            for user_alpha in param_grid['user_alpha']:\n",
        "                optimization_count += 1\n",
        "\n",
        "                params = {\n",
        "                    'no_components': no_components,\n",
        "                    'learning_rate': learning_rate,\n",
        "                    'item_alpha': item_alpha,\n",
        "                    'user_alpha': user_alpha\n",
        "                }\n",
        "\n",
        "                try:\n",
        "                    model = LightFM(\n",
        "                        loss=best_loss,\n",
        "                        no_components=no_components,\n",
        "                        learning_rate=learning_rate,\n",
        "                        item_alpha=item_alpha,\n",
        "                        user_alpha=user_alpha,\n",
        "                        random_state=42\n",
        "                    )\n",
        "\n",
        "                    model.fit(train_matrix, epochs=EPOCHS_COLLABORATIVE, num_threads=2)\n",
        "                    test_auc = auc_score(model, test_matrix, train_interactions=train_matrix).mean()\n",
        "\n",
        "                    if test_auc > best_optimized_score:\n",
        "                        best_optimized_score = test_auc\n",
        "                        best_params = params\n",
        "                        best_optimized_model = model\n",
        "\n",
        "                    print(f\"âœ“ {optimization_count}/{np.prod([len(v) for v in param_grid.values()])} - Components: {no_components}, LR: {learning_rate}, AUC: {test_auc:.4f}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"âœ— Erreur avec {params}: {e}\")\n",
        "\n",
        "print(f\"\\nğŸ† MEILLEURS HYPERPARAMÃˆTRES:\")\n",
        "for param, value in best_params.items():\n",
        "    print(f\"  {param}: {value}\")\n",
        "print(f\"ğŸ¯ Meilleur score AUC: {best_optimized_score:.4f}\")\n",
        "log_step(\"Optimisation hyperparamÃ¨tres terminÃ©e\", f\"Meilleur AUC: {best_optimized_score:.4f}, Params: {best_params}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zz1xeTiaD0eM",
        "outputId": "5820f39a-3eda-441d-86fd-186374d91356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”§ 7. OPTIMISATION DES HYPERPARAMÃˆTRES\n",
            "------------------------------\n",
            "ğŸ” Test de 16 combinaisons...\n",
            "âœ“ 1/16 - Components: 64, LR: 0.05, AUC: 0.5207\n",
            "âœ“ 2/16 - Components: 64, LR: 0.05, AUC: 0.5226\n",
            "âœ“ 3/16 - Components: 64, LR: 0.05, AUC: 0.5231\n",
            "âœ“ 4/16 - Components: 64, LR: 0.05, AUC: 0.5229\n",
            "âœ“ 5/16 - Components: 64, LR: 0.1, AUC: 0.5278\n",
            "âœ“ 6/16 - Components: 64, LR: 0.1, AUC: 0.5275\n",
            "âœ“ 7/16 - Components: 64, LR: 0.1, AUC: 0.5310\n",
            "âœ“ 8/16 - Components: 64, LR: 0.1, AUC: 0.5314\n",
            "âœ“ 9/16 - Components: 128, LR: 0.05, AUC: 0.5201\n",
            "âœ“ 10/16 - Components: 128, LR: 0.05, AUC: 0.5204\n",
            "âœ“ 11/16 - Components: 128, LR: 0.05, AUC: 0.5204\n",
            "âœ“ 12/16 - Components: 128, LR: 0.05, AUC: 0.5205\n",
            "âœ“ 13/16 - Components: 128, LR: 0.1, AUC: 0.5186\n",
            "âœ“ 14/16 - Components: 128, LR: 0.1, AUC: 0.5186\n",
            "âœ“ 15/16 - Components: 128, LR: 0.1, AUC: 0.5188\n",
            "âœ“ 16/16 - Components: 128, LR: 0.1, AUC: 0.5186\n",
            "\n",
            "ğŸ† MEILLEURS HYPERPARAMÃˆTRES:\n",
            "  no_components: 64\n",
            "  learning_rate: 0.1\n",
            "  item_alpha: 0.0001\n",
            "  user_alpha: 0.0001\n",
            "ğŸ¯ Meilleur score AUC: 0.5314\n",
            "ğŸ“ Ã‰tape loggÃ©e: Optimisation hyperparamÃ¨tres terminÃ©e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Ã‰VALUATION COMPLÃˆTE\n"
      ],
      "metadata": {
        "id": "zW_6uYlhD8Hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nğŸ“Š 8. Ã‰VALUATION COMPLÃˆTE\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Ã‰valuation sur diffÃ©rentes valeurs de k\n",
        "k_values = [5, 10, 20]\n",
        "evaluation_results = {}\n",
        "\n",
        "print(\"ğŸ“ˆ MÃ‰TRIQUES D'Ã‰VALUATION\")\n",
        "for k in k_values:\n",
        "    precision_k = precision_at_k(best_optimized_model, test_matrix, train_interactions=train_matrix, k=k).mean()\n",
        "    recall_k = recall_at_k(best_optimized_model, test_matrix, train_interactions=train_matrix, k=k).mean()\n",
        "\n",
        "    evaluation_results[f'precision@{k}'] = precision_k\n",
        "    evaluation_results[f'recall@{k}'] = recall_k\n",
        "\n",
        "    print(f\"ğŸ“Š Precision@{k}: {precision_k:.4f} | Recall@{k}: {recall_k:.4f}\")\n",
        "\n",
        "evaluation_results['auc'] = best_optimized_score\n",
        "print(f\"ğŸ“Š AUC Score: {best_optimized_score:.4f}\")\n",
        "log_step(\"Ã‰valuation modÃ¨le terminÃ©e\", f\"AUC: {best_optimized_score:.4f}, Precision@10: {evaluation_results['precision@10']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc0Cp3nvEB0m",
        "outputId": "1a7e06ce-9d97-4eac-df15-e0cb9f90e426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š 8. Ã‰VALUATION COMPLÃˆTE\n",
            "------------------------------\n",
            "ğŸ“ˆ MÃ‰TRIQUES D'Ã‰VALUATION\n",
            "ğŸ“Š Precision@5: 0.0099 | Recall@5: 0.0085\n",
            "ğŸ“Š Precision@10: 0.0117 | Recall@10: 0.0190\n",
            "ğŸ“Š Precision@20: 0.0158 | Recall@20: 0.0613\n",
            "ğŸ“Š AUC Score: 0.5314\n",
            "ğŸ“ Ã‰tape loggÃ©e: Ã‰valuation modÃ¨le terminÃ©e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. MODÃˆLE HYBRIDE\n"
      ],
      "metadata": {
        "id": "OvMf2a04EFmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nğŸ”€ 9. MODÃˆLE HYBRIDE AVEC FEATURES\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "print(\"ğŸ·ï¸ PrÃ©paration des features d'articles...\")\n",
        "\n",
        "# SÃ©lection des features catÃ©gorielles (MODIFIÃ‰ pour utiliser ARTICLE_FEATURES)\n",
        "feature_columns = [col for col in ARTICLE_FEATURES if col in articles_sample.columns]\n",
        "if not feature_columns:\n",
        "    print(f\"âŒ Aucune feature disponible parmi: {ARTICLE_FEATURES}\")\n",
        "    print(f\"ğŸ“‹ Colonnes disponibles: {list(articles_sample.columns)}\")\n",
        "    # Utiliser des features par dÃ©faut si disponibles\n",
        "    fallback_features = ['product_type_name', 'product_group_name', 'colour_group_name']\n",
        "    feature_columns = [col for col in fallback_features if col in articles_sample.columns]\n",
        "    if feature_columns:\n",
        "        print(f\"ğŸ”„ Utilisation des features par dÃ©faut: {feature_columns}\")\n",
        "    else:\n",
        "        print(\"âŒ Aucune feature utilisable trouvÃ©e - utilisation du modÃ¨le collaboratif\")\n",
        "        hybrid_model = best_optimized_model\n",
        "        hybrid_auc = best_optimized_score\n",
        "        hybrid_precision = evaluation_results['precision@10']\n",
        "        feature_columns = []\n",
        "\n",
        "if feature_columns:\n",
        "    print(f\"âœ… Features utilisÃ©es: {feature_columns}\")\n",
        "\n",
        "    articles_features = articles_sample[['article_id'] + feature_columns].copy()\n",
        "\n",
        "    # Nettoyage des valeurs manquantes\n",
        "    for col in feature_columns:\n",
        "        articles_features[col] = articles_features[col].fillna('Unknown')\n",
        "\n",
        "    # CrÃ©ation du dataset LightFM avec features\n",
        "    dataset = Dataset()\n",
        "\n",
        "    unique_users = transactions_sample['customer_id'].unique()\n",
        "    unique_items = transactions_sample['article_id'].unique()\n",
        "\n",
        "    # PrÃ©paration des features d'items\n",
        "    item_features = []\n",
        "    for _, row in articles_features.iterrows():\n",
        "        features = [f\"{col}:{row[col]}\" for col in feature_columns]\n",
        "        item_features.append((row['article_id'], features))\n",
        "\n",
        "    dataset.fit(users=unique_users,\n",
        "               items=unique_items,\n",
        "               item_features=[f\"{col}:{val}\" for col in feature_columns\n",
        "                             for val in articles_features[col].unique()])\n",
        "\n",
        "    print(f\"ğŸ“Š Dataset crÃ©Ã© avec {len(unique_users):,} utilisateurs et {len(unique_items):,} articles\")\n",
        "\n",
        "    # Construction des matrices avec features\n",
        "    interactions_matrix, weights = dataset.build_interactions(\n",
        "        [(row['customer_id'], row['article_id']) for _, row in transactions_sample.iterrows()]\n",
        "    )\n",
        "\n",
        "    item_features_matrix = dataset.build_item_features(item_features)\n",
        "\n",
        "    print(f\"ğŸ“Š Matrice d'interactions: {interactions_matrix.shape}\")\n",
        "    print(f\"ğŸ“Š Matrice de features: {item_features_matrix.shape}\")\n",
        "\n",
        "    # EntraÃ®nement du modÃ¨le hybride\n",
        "    print(f\"\\nğŸ”„ EntraÃ®nement du modÃ¨le hybride ({EPOCHS_HYBRID} epochs)...\")\n",
        "\n",
        "    hybrid_model = LightFM(\n",
        "        loss=best_loss,\n",
        "        no_components=best_params.get('no_components', 128),\n",
        "        learning_rate=best_params.get('learning_rate', 0.05),\n",
        "        item_alpha=best_params.get('item_alpha', 1e-5),\n",
        "        user_alpha=best_params.get('user_alpha', 1e-5),\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    hybrid_model.fit(interactions_matrix,\n",
        "                    item_features=item_features_matrix,\n",
        "                    epochs=EPOCHS_HYBRID,\n",
        "                    num_threads=2,\n",
        "                    verbose=True)\n",
        "\n",
        "    # Ã‰valuation du modÃ¨le hybride\n",
        "    print(\"\\nğŸ“Š Ã‰valuation du modÃ¨le hybride...\")\n",
        "\n",
        "    hybrid_auc = auc_score(hybrid_model, interactions_matrix, item_features=item_features_matrix).mean()\n",
        "    hybrid_precision = precision_at_k(hybrid_model, interactions_matrix, item_features=item_features_matrix, k=10).mean()\n",
        "\n",
        "    print(f\"ğŸ¯ ModÃ¨le Hybride - AUC: {hybrid_auc:.4f}\")\n",
        "    print(f\"ğŸ¯ ModÃ¨le Hybride - Precision@10: {hybrid_precision:.4f}\")\n",
        "\n",
        "    # Comparaison\n",
        "    print(f\"\\nğŸ“Š COMPARAISON MODÃˆLES:\")\n",
        "    print(f\"  Collaboratif - AUC: {best_optimized_score:.4f}\")\n",
        "    print(f\"  Hybride - AUC: {hybrid_auc:.4f}\")\n",
        "    improvement = ((hybrid_auc - best_optimized_score) / best_optimized_score * 100)\n",
        "    print(f\"  AmÃ©lioration: {improvement:+.2f}%\")\n",
        "    log_step(\"ModÃ¨le hybride terminÃ©\", f\"AUC Hybride: {hybrid_auc:.4f}, AmÃ©lioration: {improvement:+.2f}%\")\n",
        "\n",
        "else:\n",
        "    # Pas de features disponibles\n",
        "    hybrid_auc = best_optimized_score\n",
        "    hybrid_precision = evaluation_results['precision@10']\n",
        "    improvement = 0.0\n",
        "    print(\"ğŸ“Š Utilisation du modÃ¨le collaboratif optimisÃ© comme modÃ¨le final\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8f8lF60EJze",
        "outputId": "aaaa280b-95ae-4381-d0ef-0d62341dd0e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”€ 9. MODÃˆLE HYBRIDE AVEC FEATURES\n",
            "------------------------------\n",
            "ğŸ·ï¸ PrÃ©paration des features d'articles...\n",
            "âœ… Features utilisÃ©es: ['product_type_name', 'product_group_name', 'colour_group_name']\n",
            "ğŸ“Š Dataset crÃ©Ã© avec 998 utilisateurs et 500 articles\n",
            "ğŸ“Š Matrice d'interactions: (998, 500)\n",
            "ğŸ“Š Matrice de features: (500, 565)\n",
            "\n",
            "ğŸ”„ EntraÃ®nement du modÃ¨le hybride (5 epochs)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š Ã‰valuation du modÃ¨le hybride...\n",
            "ğŸ¯ ModÃ¨le Hybride - AUC: 0.7111\n",
            "ğŸ¯ ModÃ¨le Hybride - Precision@10: 0.1763\n",
            "\n",
            "ğŸ“Š COMPARAISON MODÃˆLES:\n",
            "  Collaboratif - AUC: 0.5314\n",
            "  Hybride - AUC: 0.7111\n",
            "  AmÃ©lioration: +33.80%\n",
            "ğŸ“ Ã‰tape loggÃ©e: ModÃ¨le hybride terminÃ©\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. PIPELINE FINAL ET TESTS\n"
      ],
      "metadata": {
        "id": "3DS70HhmEN66"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xlefLA4_wTK",
        "outputId": "664d1b79-ba13-4122-a37d-d5bc6d8634bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸš€ 10. PIPELINE FINAL ET TESTS\n",
            "------------------------------\n",
            "ğŸ”§ Initialisation du systÃ¨me de recommandation...\n",
            "âœ… SystÃ¨me de recommandation hybride initialisÃ©\n",
            "\n",
            "ğŸ§ª TESTS DU SYSTÃˆME DE RECOMMANDATION\n",
            "\n",
            "ğŸ‘¤ Recommandations pour le client 01e464bf74b13a55df22de1528eff2b33749c0cd92953b62bd22dee2de17d1fd:\n",
            "  1. Article 448509014 - Trousers (Blue) - Score: -0.553\n",
            "  2. Article 714790003 - Trousers (Blue) - Score: -0.595\n",
            "  3. Article 573085004 - Trousers (Blue) - Score: -0.597\n",
            "\n",
            "ğŸ‘¤ Recommandations pour le client 08ddd7be3e60252d2cba9dd55297a6ad0bdc1f4e244a16a8ebf61b73c56557c5:\n",
            "  1. Article 706016001 - Trousers (Black) - Score: 0.071\n",
            "  2. Article 562245046 - Trousers (Black) - Score: 0.070\n",
            "  3. Article 399201005 - Trousers (Dark Blue) - Score: 0.062\n",
            "\n",
            "ğŸ‘¤ Recommandations pour le client 0e1ca3cd38b0fd1727ef7cc963d8f5ac1f37617593d57f1b497ffa74b0937c2c:\n",
            "  1. Article 160442010 - Socks (White) - Score: -1.115\n",
            "  2. Article 372860002 - Socks (White) - Score: -1.126\n",
            "  3. Article 470789019 - Underwear bottom (Light Beige) - Score: -1.128\n",
            "\n",
            "ğŸ” TEST SIMILARITÃ‰ D'ARTICLES\n",
            "Erreur pour article 519583008: np.int64(533)\n",
            "Aucun article similaire trouvÃ©\n",
            "ğŸ“ Ã‰tape loggÃ©e: Pipeline terminÃ© avec succÃ¨s\n",
            "\n",
            "============================================================\n",
            "ğŸ‰ PIPELINE TERMINÃ‰ AVEC SUCCÃˆS !\n",
            "============================================================\n",
            "\n",
            "ğŸ“‹ CONFIGURATION UTILISÃ‰E:\n",
            "  ğŸ”§ Mode: TEST RAPIDE\n",
            "  ğŸ“‚ Chemin donnÃ©es: /content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys/data\n",
            "  ğŸ‘¥ Max utilisateurs: 1000\n",
            "  ğŸ½ Max articles: 500\n",
            "  ğŸ·ï¸ Features utilisÃ©es: 3\n",
            "  ğŸ¤– Type de modÃ¨le: Hybride\n",
            "\n",
            "ğŸ“Š RÃ‰SULTATS FINAUX:\n",
            "  ğŸ‘¥ Utilisateurs traitÃ©s: 998\n",
            "  ğŸ‘• Articles traitÃ©s: 500\n",
            "  ğŸ¤ ModÃ¨le collaboratif AUC: 0.5314\n",
            "  ğŸ”€ ModÃ¨le final AUC: 0.7111\n",
            "  ğŸ“ˆ AmÃ©lioration hybride: +33.80%\n",
            "\n",
            "ğŸ’¾ FICHIERS SAUVEGARDÃ‰S DANS: /content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys/outputs/run_20250928_113619\n",
            "  ğŸ“ sample_data.pkl\n",
            "  ğŸ“ prepared_data.pkl\n",
            "  ğŸ“ final_recommendation_system.pkl\n",
            "  ğŸ“ execution_log.txt\n",
            "\n",
            "ğŸ†” ID EXÃ‰CUTION: run_20250928_113619\n",
            "âœ… SystÃ¨me de recommandation opÃ©rationnel\n",
            "âœ… Tests de validation effectuÃ©s\n",
            "\n",
            "ğŸ’¡ Pour un run complet, changez QUICK_TEST_MODE = False dans la config\n",
            "\n",
            "ğŸ¯ RECOMMANDATIONS POUR LA PROCHAINE Ã‰TAPE:\n",
            "  ğŸš€ Testez en mode complet pour de meilleures performances\n",
            "  ğŸ“Š Analysez les rÃ©sultats dans le fichier de log\n",
            "\n",
            "ğŸš€ Pipeline prÃªt pour la production !\n",
            "\n",
            "ğŸ“ Log complet disponible: /content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys/outputs/run_20250928_113619/execution_log.txt\n",
            "\n",
            "============================================================\n",
            "ğŸ“‹ GUIDE RAPIDE POUR UTILISER CE PIPELINE\n",
            "============================================================\n",
            "\n",
            "ğŸ”§ POUR PERSONNALISER LE PIPELINE:\n",
            "\n",
            "1. CHANGEZ CES VARIABLES AU DÃ‰BUT DU CODE:\n",
            "   â€¢ USER_BASE_PATH = \"/votre/chemin/vers/donnÃ©es\"\n",
            "   â€¢ USER_DATA_FOLDER = \"nom_dossier_csv\"\n",
            "   â€¢ QUICK_TEST_MODE = True/False\n",
            "\n",
            "2. AJUSTEZ LES PARAMÃˆTRES SELON VOS BESOINS:\n",
            "   â€¢ USER_QUICK_MAX_USERS = nombre d'utilisateurs max\n",
            "   â€¢ USER_ARTICLE_FEATURES = ['colonne1', 'colonne2', ...]\n",
            "   â€¢ USER_LOSS_FUNCTIONS = ['warp', 'bpr', 'logistic']\n",
            "\n",
            "3. LANCEZ LE CODE ET VÃ‰RIFIEZ LES RÃ‰SULTATS DANS:\n",
            "   /content/drive/MyDrive/PSL/00-RecommanderSystem/h2m-recsys/outputs/run_20250928_113619\n",
            "\n",
            "ğŸš€ PRÃŠT Ã€ UTILISER - AUCUNE AUTRE MODIFICATION NÃ‰CESSAIRE!\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nğŸš€ 10. PIPELINE FINAL ET TESTS\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Classe pour le systÃ¨me de recommandation\n",
        "class HMRecommendationSystem:\n",
        "    def __init__(self, model, dataset=None, item_features_matrix=None, user_encoder=None, item_encoder=None):\n",
        "        self.model = model\n",
        "        self.dataset = dataset\n",
        "        self.item_features_matrix = item_features_matrix\n",
        "        self.user_encoder = user_encoder\n",
        "        self.item_encoder = item_encoder\n",
        "        self.is_hybrid = dataset is not None and item_features_matrix is not None\n",
        "\n",
        "    def get_user_recommendations(self, customer_id, n_recommendations=10):\n",
        "        \"\"\"Obtient des recommandations pour un utilisateur\"\"\"\n",
        "        try:\n",
        "            if self.is_hybrid:\n",
        "                # Mode hybride - utilise le dataset LightFM\n",
        "                user_mapping = self.dataset.mapping()[0]\n",
        "                item_mapping = self.dataset.mapping()[2]\n",
        "\n",
        "                if customer_id not in user_mapping:\n",
        "                    print(f\"Utilisateur {customer_id} non trouvÃ© dans le dataset hybride\")\n",
        "                    return []\n",
        "\n",
        "                user_id = user_mapping[customer_id]\n",
        "                item_ids = list(range(len(item_mapping)))\n",
        "                user_ids = [user_id] * len(item_ids)\n",
        "\n",
        "                scores = self.model.predict(user_ids, item_ids, item_features=self.item_features_matrix)\n",
        "\n",
        "                top_items = np.argsort(scores)[::-1][:n_recommendations]\n",
        "                reverse_item_mapping = {v: k for k, v in item_mapping.items()}\n",
        "                top_articles = [reverse_item_mapping[i] for i in top_items]\n",
        "                top_scores = scores[top_items]\n",
        "\n",
        "            else:\n",
        "                # Mode collaboratif classique\n",
        "                user_id = self.user_encoder.transform([customer_id])[0]\n",
        "\n",
        "                # CrÃ©er des arrays pour tous les articles\n",
        "                user_ids = np.array([user_id] * len(self.item_encoder.classes_))\n",
        "                item_ids = np.arange(len(self.item_encoder.classes_))\n",
        "\n",
        "                scores = self.model.predict(user_ids, item_ids)\n",
        "\n",
        "                top_items = np.argsort(scores)[::-1][:n_recommendations]\n",
        "                top_articles = self.item_encoder.inverse_transform(top_items)\n",
        "                top_scores = scores[top_items]\n",
        "\n",
        "            return list(zip(top_articles, top_scores))\n",
        "\n",
        "        except (ValueError, KeyError) as e:\n",
        "            print(f\"Erreur pour utilisateur {customer_id}: {e}\")\n",
        "            return []\n",
        "\n",
        "    def get_similar_items(self, article_id, n_similar=10):\n",
        "        \"\"\"Trouve des articles similaires basÃ©s sur les embeddings\"\"\"\n",
        "        try:\n",
        "            if self.is_hybrid:\n",
        "                # Mode hybride\n",
        "                item_mapping = self.dataset.mapping()[2]\n",
        "                if article_id not in item_mapping:\n",
        "                    print(f\"Article {article_id} non trouvÃ© dans le dataset hybride\")\n",
        "                    return []\n",
        "\n",
        "                item_id = item_mapping[article_id]\n",
        "            else:\n",
        "                # Mode collaboratif\n",
        "                item_id = self.item_encoder.transform([article_id])[0]\n",
        "\n",
        "            # Obtenir les embeddings d'articles\n",
        "            item_embeddings = self.model.item_embeddings\n",
        "\n",
        "            # Calculer la similaritÃ© cosinus\n",
        "            target_embedding = item_embeddings[item_id]\n",
        "            similarities = np.dot(item_embeddings, target_embedding)\n",
        "\n",
        "            # Articles les plus similaires (exclure l'article lui-mÃªme)\n",
        "            similar_items = np.argsort(similarities)[::-1][1:n_similar+1]\n",
        "\n",
        "            if self.is_hybrid:\n",
        "                reverse_item_mapping = {v: k for k, v in item_mapping.items()}\n",
        "                similar_articles = [reverse_item_mapping[i] for i in similar_items]\n",
        "            else:\n",
        "                similar_articles = self.item_encoder.inverse_transform(similar_items)\n",
        "\n",
        "            similarity_scores = similarities[similar_items]\n",
        "\n",
        "            return list(zip(similar_articles, similarity_scores))\n",
        "\n",
        "        except (ValueError, KeyError) as e:\n",
        "            print(f\"Erreur pour article {article_id}: {e}\")\n",
        "            return []\n",
        "\n",
        "# Initialisation du systÃ¨me\n",
        "print(\"ğŸ”§ Initialisation du systÃ¨me de recommandation...\")\n",
        "\n",
        "if feature_columns:\n",
        "    # SystÃ¨me hybride\n",
        "    recommender = HMRecommendationSystem(\n",
        "        model=hybrid_model,\n",
        "        dataset=dataset,\n",
        "        item_features_matrix=item_features_matrix,\n",
        "        user_encoder=user_encoder,\n",
        "        item_encoder=item_encoder\n",
        "    )\n",
        "    print(\"âœ… SystÃ¨me de recommandation hybride initialisÃ©\")\n",
        "else:\n",
        "    # SystÃ¨me collaboratif\n",
        "    recommender = HMRecommendationSystem(\n",
        "        model=best_optimized_model,\n",
        "        user_encoder=user_encoder,\n",
        "        item_encoder=item_encoder\n",
        "    )\n",
        "    print(\"âœ… SystÃ¨me de recommandation collaboratif initialisÃ©\")\n",
        "\n",
        "# Tests du systÃ¨me\n",
        "print(\"\\nğŸ§ª TESTS DU SYSTÃˆME DE RECOMMANDATION\")\n",
        "\n",
        "# Test avec quelques utilisateurs\n",
        "test_users = transactions_sample['customer_id'].unique()[:3]\n",
        "\n",
        "for customer_id in test_users:\n",
        "    print(f\"\\nğŸ‘¤ Recommandations pour le client {customer_id}:\")\n",
        "    recommendations = recommender.get_user_recommendations(customer_id, 3)\n",
        "\n",
        "    if recommendations:\n",
        "        for i, (article_id, score) in enumerate(recommendations[:3], 1):\n",
        "            article_info = articles_sample[articles_sample['article_id'] == article_id]\n",
        "            if not article_info.empty and 'product_type_name' in article_info.columns:\n",
        "                product_name = article_info.iloc[0].get('product_type_name', 'N/A')\n",
        "                color = article_info.iloc[0].get('colour_group_name', 'N/A')\n",
        "                print(f\"  {i}. Article {article_id} - {product_name} ({color}) - Score: {score:.3f}\")\n",
        "            else:\n",
        "                print(f\"  {i}. Article {article_id} - Score: {score:.3f}\")\n",
        "    else:\n",
        "        print(\"  Aucune recommandation disponible\")\n",
        "\n",
        "# Test similaritÃ© d'articles\n",
        "print(f\"\\nğŸ” TEST SIMILARITÃ‰ D'ARTICLES\")\n",
        "test_article = transactions_sample['article_id'].iloc[0]\n",
        "similar_items = recommender.get_similar_items(test_article, 3)\n",
        "\n",
        "if similar_items:\n",
        "    print(f\"Articles similaires Ã  {test_article}:\")\n",
        "    for i, (article_id, similarity) in enumerate(similar_items[:3], 1):\n",
        "        print(f\"  {i}. Article {article_id} - SimilaritÃ©: {similarity:.3f}\")\n",
        "else:\n",
        "    print(\"Aucun article similaire trouvÃ©\")\n",
        "\n",
        "# Sauvegarde finale (MODIFIÃ‰ pour inclure la configuration utilisateur)\n",
        "final_results = {\n",
        "    'user_configuration': {\n",
        "        'BASE_PATH': BASE_PATH,\n",
        "        'DATA_PATH': DATA_PATH,\n",
        "        'QUICK_TEST_MODE': QUICK_TEST_MODE,\n",
        "        'MAX_USERS': MAX_USERS,\n",
        "        'MAX_ARTICLES': MAX_ARTICLES,\n",
        "        'EPOCHS_COLLABORATIVE': EPOCHS_COLLABORATIVE,\n",
        "        'EPOCHS_HYBRID': EPOCHS_HYBRID,\n",
        "        'ARTICLE_FEATURES': ARTICLE_FEATURES,\n",
        "        'LOSS_FUNCTIONS': LOSS_FUNCTIONS,\n",
        "        'feature_columns_used': feature_columns\n",
        "    },\n",
        "    'recommender': recommender,\n",
        "    'collaborative_auc': best_optimized_score,\n",
        "    'hybrid_auc': hybrid_auc,\n",
        "    'improvement': improvement,\n",
        "    'best_params': best_params,\n",
        "    'evaluation_results': evaluation_results,\n",
        "    'model_type': 'hybrid' if feature_columns else 'collaborative'\n",
        "}\n",
        "\n",
        "final_path = f\"{OUTPUTS_PATH}/final_recommendation_system.pkl\"\n",
        "with open(final_path, 'wb') as f:\n",
        "    pickle.dump(final_results, f)\n",
        "\n",
        "log_step(\"Pipeline terminÃ© avec succÃ¨s\", f\"Fichiers sauvegardÃ©s dans: {OUTPUTS_PATH}\")\n",
        "\n",
        "# =============================================================================\n",
        "# RÃ‰SUMÃ‰ FINAL\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ‰ PIPELINE TERMINÃ‰ AVEC SUCCÃˆS !\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nğŸ“‹ CONFIGURATION UTILISÃ‰E:\")\n",
        "print(f\"  ğŸ”§ Mode: {'TEST RAPIDE' if QUICK_TEST_MODE else 'COMPLET'}\")\n",
        "print(f\"  ğŸ“‚ Chemin donnÃ©es: {DATA_PATH}\")\n",
        "print(f\"  ğŸ‘¥ Max utilisateurs: {MAX_USERS}\")\n",
        "print(f\"  ğŸ½ Max articles: {MAX_ARTICLES}\")\n",
        "print(f\"  ğŸ·ï¸ Features utilisÃ©es: {len(feature_columns) if feature_columns else 0}\")\n",
        "print(f\"  ğŸ¤– Type de modÃ¨le: {'Hybride' if feature_columns else 'Collaboratif'}\")\n",
        "\n",
        "print(f\"\\nğŸ“Š RÃ‰SULTATS FINAUX:\")\n",
        "print(f\"  ğŸ‘¥ Utilisateurs traitÃ©s: {num_users:,}\")\n",
        "print(f\"  ğŸ‘• Articles traitÃ©s: {num_items:,}\")\n",
        "print(f\"  ğŸ¤ ModÃ¨le collaboratif AUC: {best_optimized_score:.4f}\")\n",
        "print(f\"  ğŸ”€ ModÃ¨le final AUC: {hybrid_auc:.4f}\")\n",
        "if feature_columns:\n",
        "    print(f\"  ğŸ“ˆ AmÃ©lioration hybride: {improvement:+.2f}%\")\n",
        "\n",
        "print(f\"\\nğŸ’¾ FICHIERS SAUVEGARDÃ‰S DANS: {OUTPUTS_PATH}\")\n",
        "print(f\"  ğŸ“ sample_data.pkl\")\n",
        "print(f\"  ğŸ“ prepared_data.pkl\")\n",
        "print(f\"  ğŸ“ final_recommendation_system.pkl\")\n",
        "print(f\"  ğŸ“ execution_log.txt\")\n",
        "\n",
        "if CREATE_TIMESTAMPED_OUTPUT:\n",
        "    print(f\"\\nğŸ†” ID EXÃ‰CUTION: {run_id}\")\n",
        "\n",
        "print(\"âœ… SystÃ¨me de recommandation opÃ©rationnel\")\n",
        "print(\"âœ… Tests de validation effectuÃ©s\")\n",
        "\n",
        "if QUICK_TEST_MODE:\n",
        "    print(\"\\nğŸ’¡ Pour un run complet, changez QUICK_TEST_MODE = False dans la config\")\n",
        "\n",
        "print(f\"\\nğŸ¯ RECOMMANDATIONS POUR LA PROCHAINE Ã‰TAPE:\")\n",
        "if not feature_columns:\n",
        "    print(\"  ğŸ“‹ VÃ©rifiez la disponibilitÃ© des features d'articles dans vos donnÃ©es\")\n",
        "    print(\"  ğŸ”§ Ajustez USER_ARTICLE_FEATURES selon vos colonnes disponibles\")\n",
        "if QUICK_TEST_MODE:\n",
        "    print(\"  ğŸš€ Testez en mode complet pour de meilleures performances\")\n",
        "print(\"  ğŸ“Š Analysez les rÃ©sultats dans le fichier de log\")\n",
        "\n",
        "print(\"\\nğŸš€ Pipeline prÃªt pour la production !\")\n",
        "\n",
        "# Finalisation du log (MODIFIÃ‰ pour inclure la configuration)\n",
        "with open(log_file, 'a') as f:\n",
        "    f.write(\"=\"*50 + \"\\n\")\n",
        "    f.write(f\"EXÃ‰CUTION TERMINÃ‰E Ã€: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "    f.write(f\"CONFIGURATION FINALE:\\n\")\n",
        "    f.write(f\"  - Mode: {'TEST RAPIDE' if QUICK_TEST_MODE else 'COMPLET'}\\n\")\n",
        "    f.write(f\"  - Chemin donnÃ©es: {DATA_PATH}\\n\")\n",
        "    f.write(f\"  - Features utilisÃ©es: {feature_columns}\\n\")\n",
        "    f.write(f\"RÃ‰SULTATS FINAUX:\\n\")\n",
        "    f.write(f\"  - Utilisateurs: {num_users:,}\\n\")\n",
        "    f.write(f\"  - Articles: {num_items:,}\\n\")\n",
        "    f.write(f\"  - AUC Collaboratif: {best_optimized_score:.4f}\\n\")\n",
        "    f.write(f\"  - AUC Final: {hybrid_auc:.4f}\\n\")\n",
        "    if feature_columns:\n",
        "        f.write(f\"  - AmÃ©lioration: {improvement:+.2f}%\\n\")\n",
        "    f.write(f\"  - Type modÃ¨le: {'Hybride' if feature_columns else 'Collaboratif'}\\n\")\n",
        "\n",
        "print(f\"\\nğŸ“ Log complet disponible: {log_file}\")\n",
        "\n",
        "# =============================================================================\n",
        "# ğŸ“‹ GUIDE RAPIDE POUR L'UTILISATEUR\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“‹ GUIDE RAPIDE POUR UTILISER CE PIPELINE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\"\"\n",
        "ğŸ”§ POUR PERSONNALISER LE PIPELINE:\n",
        "\n",
        "1. CHANGEZ CES VARIABLES AU DÃ‰BUT DU CODE:\n",
        "   â€¢ USER_BASE_PATH = \"/votre/chemin/vers/donnÃ©es\"\n",
        "   â€¢ USER_DATA_FOLDER = \"nom_dossier_csv\"\n",
        "   â€¢ QUICK_TEST_MODE = True/False\n",
        "\n",
        "2. AJUSTEZ LES PARAMÃˆTRES SELON VOS BESOINS:\n",
        "   â€¢ USER_QUICK_MAX_USERS = nombre d'utilisateurs max\n",
        "   â€¢ USER_ARTICLE_FEATURES = ['colonne1', 'colonne2', ...]\n",
        "   â€¢ USER_LOSS_FUNCTIONS = ['warp', 'bpr', 'logistic']\n",
        "\n",
        "3. LANCEZ LE CODE ET VÃ‰RIFIEZ LES RÃ‰SULTATS DANS:\n",
        "   {OUTPUTS_PATH}\n",
        "\n",
        "ğŸš€ PRÃŠT Ã€ UTILISER - AUCUNE AUTRE MODIFICATION NÃ‰CESSAIRE!\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*60)"
      ]
    }
  ]
}